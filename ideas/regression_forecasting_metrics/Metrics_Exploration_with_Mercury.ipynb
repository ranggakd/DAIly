{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1Hk0pcErujl"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ranggakd/DAIly/blob/main/ideas/regression_forecasting_metrics/Metrics_Exploration.ipynb)\n",
        "[![Open Medium Story](https://img.shields.io/badge/-Open_Medium_Story-black?logo=medium)](https://medium.com/@ranggakd/forecasting-metrics-im-new-i-tried-let-s-talk-f6208c55bc3b)\n",
        "[![Open DEV Post](https://img.shields.io/badge/-Open_DEV_Post-black?logo=dev.to)](https://dev.to/ranggakd/so-i-explored-forecasting-metrics-now-i-want-your-two-cents-30p0)\n",
        "\n",
        "There is another version of this Jupyter Notebook with Google Colab compatible. More explanation available on Medium or DEV.to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y0PJKPmsxBi",
        "outputId": "e745df21-2126-4658-a6be-eb1ece439a81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.11.1\n",
            "pandas==2.0.3\n",
            "numpy==1.25.2\n",
            "matplotlib==3.7.2\n",
            "matplotlib-inline==0.1.6\n",
            "statsmodels==0.14.0\n",
            "scikit-learn==1.3.0\n",
            "plotly==5.16.0\n",
            "mercury==2.3.6\n"
          ]
        }
      ],
      "source": [
        "#@markdown *Last running requirement version*\n",
        "\n",
        "# !python -V\n",
        "\n",
        "# uncomment line below if you are using Linux or Google Colab\n",
        "# !pip freeze | grep -w 'pandas'\n",
        "# !pip freeze | grep -w 'numpy'\n",
        "# !pip freeze | grep -w 'matplotlib'\n",
        "# !pip freeze | grep -w 'statsmodels'\n",
        "# !pip freeze | grep -w 'scikit-learn'\n",
        "# !pip freeze | grep -w 'plotly'\n",
        "# !pip freeze | grep -w 'mercury'\n",
        "\n",
        "# uncomment line below if you are using Windows\n",
        "# !pip freeze | findstr /C:\"pandas\"\n",
        "# !pip freeze | findstr /C:\"numpy\"\n",
        "# !pip freeze | findstr /C:\"matplotlib\"\n",
        "# !pip freeze | findstr /C:\"statsmodels\"\n",
        "# !pip freeze | findstr /C:\"scikit-learn\"\n",
        "# !pip freeze | findstr /C:\"plotly\"\n",
        "# !pip freeze | findstr /C:\"mercury\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ›ˆ **Note on the Dataset and Model Selection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Important**: The results derived from our analysis might reflect certain biases, as they are based on a synthetic dataset and an experimental model.\n",
        "\n",
        "Remember, always exercise caution and discernment when interpreting the results, given the nature of our dataset and model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2m822a8Cou8_"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import warnings\n",
        "import random\n",
        "from typing import Union, Callable, Any, TypeVar\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import mercury as mr\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "from plotly import graph_objects as go\n",
        "\n",
        "# xkcd-styled & humor sans font installed to give semi-sarcasm graph\n",
        "plt.xkcd()\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "USE_OLD_TYPING = sys.version_info < (3, 9)\n",
        "\n",
        "if USE_OLD_TYPING:\n",
        "    from typing import Tuple as tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SPnTCmI6ou9B"
      },
      "outputs": [],
      "source": [
        "# constants\n",
        "R2 = 'r2'\n",
        "MAE = 'mae'\n",
        "MSE = 'mse'\n",
        "RMSE = 'rmse'\n",
        "MASE = 'mase'\n",
        "MAPE = 'mape'\n",
        "SMAPE = 'smape'\n",
        "MBD = 'mbd'\n",
        "HUNDRED_PERCENTAGE = 100\n",
        "PERFECT_THRESHOLD = 0\n",
        "ACCEPTABLE_THRESHOLD = .05\n",
        "MODERATE_THRESHOLD = .1\n",
        "HIGH_THRESHOLD = .2\n",
        "VERY_HIGH_THRESHOLD = .3\n",
        "EXCEEDINGLY_HIGH_THRESHOLD = 1\n",
        "PERFECT = \"Perfect\"\n",
        "VERY_ACCEPTABLE = \"Very Acceptable\"\n",
        "ACCEPTABLE = \"Acceptable\"\n",
        "MODERATE = \"Moderate\"\n",
        "HIGH = \"High\"\n",
        "VERY_HIGH = \"Very High\"\n",
        "EXCEEDINGLY_HIGH = \"Exceedingly High\"\n",
        "R2_PERFECT_THRESHOLD = 1\n",
        "R2_VERY_ACCEPTABLE_THRESHOLD = .95\n",
        "R2_ACCEPTABLE_THRESHOLD = .9\n",
        "R2_MODERATE_THRESHOLD = .8\n",
        "R2_HIGH_THRESHOLD = .7\n",
        "R2_VERY_HIGH_THRESHOLD = .5\n",
        "R2_EXCEEDINGLY_HIGH_THRESHOLD = 0\n",
        "NOT_EXPLAIN_VARIABILITY = \"Doesn't Explain Variablity\"\n",
        "WORSE_THAN_MEAN_MODEL = \"Worse Than Simple Mean Model\"\n",
        "BETTER_THAN_NAIVE_LOW = 0.1\n",
        "BETTER_THAN_NAIVE_MED = 0.5\n",
        "BETTER_THAN_NAIVE_HIGH = 0.9\n",
        "NAIVE_THRESHOLD = 1\n",
        "WORSE_THAN_NAIVE_MODEL = \"Worse Than Naive Forecast Model\"\n",
        "EQUIVALENT_TO_NAIVE_MODEL = \"Equivalent to Naive Model\"\n",
        "OVERESTIMATION = 'Overestimation'\n",
        "UNDERESTIMATION = 'Underestimation'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C94JCj2Qou9C"
      },
      "outputs": [],
      "source": [
        "T = TypeVar('T', bound=Callable[..., Any])\n",
        "\n",
        "def catch_warning_decorator(func: T) -> T:\n",
        "     '''Decorator to catch and print `UndefinedMetricWarning` warnings.'''\n",
        "     def wrapper(*args: Any, **kwargs: Any) -> Any:\n",
        "          with warnings.catch_warnings(record=True) as w:\n",
        "               warnings.simplefilter('always')\n",
        "               result = func(*args, **kwargs)\n",
        "               if w and isinstance(w[-1].message, UndefinedMetricWarning):\n",
        "                    print(f\"Warning: {w[-1].message}\")\n",
        "          return result\n",
        "     return wrapper\n",
        "\n",
        "def autoreg_predict(train: pd.Series,\n",
        "                    test: pd.Series\n",
        "                    ) -> pd.Series:\n",
        "    '''Predict using AutoReg with lags = 1 and trend = ct'''\n",
        "    # Training the AutoReg model with lags set to 1\n",
        "    model = AutoReg(train, lags=1, trend='ct')\n",
        "    model = model.fit()\n",
        "    # Making predictions\n",
        "    predictions = model.predict(start=len(train), end=len(train)+len(test)-1)\n",
        "    return predictions\n",
        "\n",
        "def offsetmodel_predict(series: pd.Series,\n",
        "                        train_size: int,\n",
        "                        offset: float = .01) -> pd.Series:\n",
        "    '''Predict using Offset Model with default 1% distance of the range'''\n",
        "    dist = offset * (series.max()-series.min())\n",
        "    predictions = series[train_size:] + dist\n",
        "    return predictions\n",
        "\n",
        "def negoffsetmodel_predict(series: pd.Series,\n",
        "                        train_size: int,\n",
        "                        offset: float = .01) -> pd.Series:\n",
        "    '''Predict using Negative Offset Model with default 1% distance of the range'''\n",
        "    dist = offset * (series.max()-series.min())\n",
        "    predictions = series[train_size:] - dist\n",
        "    return predictions\n",
        "\n",
        "def randomoffsetmodel_predict(series: pd.Series,\n",
        "                              train_size: int,\n",
        "                              offset: float = .01) -> pd.Series:\n",
        "    '''Predict using Random Offset Model with default 1% distance of the range'''\n",
        "    dist = offset * (series.max() - series.min())\n",
        "    # Get the test series\n",
        "    test_series = series[train_size:]\n",
        "    # Generate a random sign (-1 or 1) for each data point in the test series\n",
        "    random_signs = [random.choice([-1, 1]) for _ in range(len(test_series))]\n",
        "    predictions = test_series + dist * pd.Series(random_signs, index=test_series.index)\n",
        "    return predictions\n",
        "\n",
        "def contains_zero(arr: np.ndarray) -> bool:\n",
        "    '''Check whether the array contains zero'''\n",
        "    return np.any(arr == 0)\n",
        "\n",
        "def contains_non_negative(arr: np.ndarray) -> bool:\n",
        "    '''Check whether the array contains non-negative values'''\n",
        "    return np.all(arr >= 0)\n",
        "\n",
        "def contains_non_positive(arr: np.ndarray) -> bool:\n",
        "    '''Check whether the array contains non-positive values'''\n",
        "    return np.all(arr <= 0)\n",
        "\n",
        "def rmse(y_true: pd.Series,\n",
        "         y_pred: pd.Series) -> float:\n",
        "    \"\"\"Compute the Root Mean Squared Error (RMSE).\"\"\"\n",
        "    return mse(y_true, y_pred) ** .5\n",
        "\n",
        "def mase(y_true: pd.Series,\n",
        "         y_pred: pd.Series,\n",
        "         y_train: pd.Series) -> float:\n",
        "    \"\"\"Compute the Mean Absolute Scaled Error (MASE).\"\"\"\n",
        "    # Compute the mean absolute error of the forecast\n",
        "    og_mae = mae(y_true, y_pred)\n",
        "    # Compute the mean absolute error of the naive method on the training data\n",
        "    nf_mae = mae(y_train[1:], y_train[:-1])\n",
        "    return og_mae / nf_mae\n",
        "\n",
        "def smape(y_true: pd.Series,\n",
        "          y_pred: pd.Series) -> float:\n",
        "     \"\"\"Compute the Symmetric Mean Absolute Percentage Error (sMAPE).\"\"\"\n",
        "     numerator = np.abs(y_pred - y_true)\n",
        "     denominator = (np.abs(y_pred) + np.abs(y_true))\n",
        "     return 100 * np.mean(2 * numerator / denominator)\n",
        "\n",
        "def mbd(y_true: pd.Series,\n",
        "        y_pred: pd.Series,\n",
        "        epsilon: float = 1e-10) -> tuple[str, float]:\n",
        "     \"\"\"Compute the Mean Bias Deviation (MBD) and its bias.\"\"\"\n",
        "     numerator = (y_pred - y_true)\n",
        "     denominator = (y_true + epsilon)\n",
        "     if np.sum(numerator) > 0 and np.sum(denominator) > 0:\n",
        "          bias = OVERESTIMATION\n",
        "     elif np.sum(numerator) < 0 and np.sum(denominator) > 0:\n",
        "          bias = UNDERESTIMATION\n",
        "     elif np.sum(numerator) > 0 and np.sum(denominator) < 0:\n",
        "          bias = OVERESTIMATION\n",
        "     elif np.sum(numerator) < 0 and np.sum(denominator) < 0:\n",
        "          bias = UNDERESTIMATION\n",
        "     return bias, 100 * np.mean(numerator / denominator)\n",
        "\n",
        "def categorize_metrics(metric: float, y_min: float, y_max: float) -> str:\n",
        "     '''Categorize standard error metrics (MAE, MSE, RMSE) into 7 categories'''\n",
        "     normalized_error = metric / (y_max - y_min)\n",
        "     if normalized_error == PERFECT_THRESHOLD:\n",
        "          return PERFECT\n",
        "     elif normalized_error <= ACCEPTABLE_THRESHOLD:\n",
        "          return VERY_ACCEPTABLE\n",
        "     elif normalized_error <= MODERATE_THRESHOLD:\n",
        "          return ACCEPTABLE\n",
        "     elif normalized_error <= HIGH_THRESHOLD:\n",
        "          return MODERATE\n",
        "     elif normalized_error <= VERY_HIGH_THRESHOLD:\n",
        "          return HIGH\n",
        "     elif normalized_error <= EXCEEDINGLY_HIGH_THRESHOLD:\n",
        "          return VERY_HIGH\n",
        "     else:\n",
        "          return EXCEEDINGLY_HIGH\n",
        "\n",
        "def emoji_categorize_metrics(metric: float, y_min: float, y_max: float) -> str:\n",
        "     '''Categorize standard error metrics (MAE, MSE, RMSE) into 7 emoji categories'''\n",
        "     normalized_error = metric / (y_max - y_min)\n",
        "     if normalized_error == PERFECT_THRESHOLD:\n",
        "          return 'ðŸ’¯'\n",
        "     elif normalized_error <= ACCEPTABLE_THRESHOLD:\n",
        "          return 'ðŸ‘Œ'\n",
        "     elif normalized_error <= MODERATE_THRESHOLD:\n",
        "          return 'âœ”ï¸'\n",
        "     elif normalized_error <= HIGH_THRESHOLD:\n",
        "          return 'â—'\n",
        "     elif normalized_error <= VERY_HIGH_THRESHOLD:\n",
        "          return 'âŒ'\n",
        "     elif normalized_error <= EXCEEDINGLY_HIGH_THRESHOLD:\n",
        "          return 'ðŸ’€'\n",
        "     else:\n",
        "          return 'â˜ '\n",
        "\n",
        "def categorize_mse(mse: float, y_min: float, y_max: float) -> str:\n",
        "     '''Categorize MSE error metrics into 7 categories'''\n",
        "     # Apply square root to mse before categorizing\n",
        "     rmse = mse ** .5\n",
        "     return categorize_metrics(rmse, y_min, y_max)\n",
        "\n",
        "def emoji_categorize_mse(mse: float, y_min: float, y_max: float) -> str:\n",
        "     '''Categorize MSE error metrics into 7 emoji categories'''\n",
        "     # Apply square root to mse before categorizing\n",
        "     rmse = mse ** .5\n",
        "     return emoji_categorize_metrics(rmse, y_min, y_max)\n",
        "\n",
        "def categorize_pe(pe: float) -> str:\n",
        "     '''Categorize PEs error metrics into categories based on magnitude.'''\n",
        "     if pe == PERFECT_THRESHOLD:\n",
        "          return PERFECT\n",
        "     elif pe <= ACCEPTABLE_THRESHOLD*HUNDRED_PERCENTAGE:\n",
        "          return VERY_ACCEPTABLE\n",
        "     elif pe <= MODERATE_THRESHOLD*HUNDRED_PERCENTAGE:\n",
        "          return ACCEPTABLE\n",
        "     elif pe <= HIGH_THRESHOLD*HUNDRED_PERCENTAGE:\n",
        "          return MODERATE\n",
        "     elif pe <= VERY_HIGH_THRESHOLD*HUNDRED_PERCENTAGE:\n",
        "          return HIGH\n",
        "     elif pe <= EXCEEDINGLY_HIGH_THRESHOLD*HUNDRED_PERCENTAGE:\n",
        "          return VERY_HIGH\n",
        "     else:\n",
        "          return EXCEEDINGLY_HIGH\n",
        "\n",
        "def emoji_categorize_pe(pe: float) -> str:\n",
        "     '''Categorize PEs error metrics into emoji categories based on magnitude.'''\n",
        "     if pe == PERFECT_THRESHOLD:\n",
        "          return 'ðŸ’¯'\n",
        "     elif pe <= ACCEPTABLE_THRESHOLD*HUNDRED_PERCENTAGE:\n",
        "          return 'ðŸ‘Œ'\n",
        "     elif pe <= MODERATE_THRESHOLD*HUNDRED_PERCENTAGE:\n",
        "          return 'âœ”ï¸'\n",
        "     elif pe <= HIGH_THRESHOLD*HUNDRED_PERCENTAGE:\n",
        "          return 'â—'\n",
        "     elif pe <= VERY_HIGH_THRESHOLD*HUNDRED_PERCENTAGE:\n",
        "          return 'âŒ'\n",
        "     elif pe <= EXCEEDINGLY_HIGH_THRESHOLD*HUNDRED_PERCENTAGE:\n",
        "          return 'ðŸ’€'\n",
        "     else:\n",
        "          return 'â˜ '\n",
        "\n",
        "def categorize_r2(r2: float) -> str:\n",
        "     '''Categorize R2 score into 9 categories'''\n",
        "     if r2 == R2_PERFECT_THRESHOLD:\n",
        "          return PERFECT\n",
        "     elif r2 >= R2_VERY_ACCEPTABLE_THRESHOLD:\n",
        "          return VERY_ACCEPTABLE\n",
        "     elif r2 >= R2_ACCEPTABLE_THRESHOLD:\n",
        "          return ACCEPTABLE\n",
        "     elif r2 >= R2_MODERATE_THRESHOLD:\n",
        "          return MODERATE\n",
        "     elif r2 >= R2_HIGH_THRESHOLD:\n",
        "          return HIGH\n",
        "     elif r2 >= R2_VERY_HIGH_THRESHOLD:\n",
        "          return VERY_HIGH\n",
        "     elif r2 > R2_EXCEEDINGLY_HIGH_THRESHOLD:\n",
        "          return EXCEEDINGLY_HIGH\n",
        "     elif r2 == R2_EXCEEDINGLY_HIGH_THRESHOLD:\n",
        "          return NOT_EXPLAIN_VARIABILITY\n",
        "     else:\n",
        "          return WORSE_THAN_MEAN_MODEL\n",
        "\n",
        "def emoji_categorize_r2(r2: float) -> str:\n",
        "     '''Categorize R2 score into 9 emoji categories'''\n",
        "     if r2 == R2_PERFECT_THRESHOLD:\n",
        "          return 'ðŸ’¯'\n",
        "     elif r2 >= R2_VERY_ACCEPTABLE_THRESHOLD:\n",
        "          return 'ðŸ‘Œ'\n",
        "     elif r2 >= R2_ACCEPTABLE_THRESHOLD:\n",
        "          return 'âœ”ï¸'\n",
        "     elif r2 >= R2_MODERATE_THRESHOLD:\n",
        "          return 'â—'\n",
        "     elif r2 >= R2_HIGH_THRESHOLD:\n",
        "          return 'âŒ'\n",
        "     elif r2 >= R2_VERY_HIGH_THRESHOLD:\n",
        "          return 'ðŸ’€'\n",
        "     elif r2 > R2_EXCEEDINGLY_HIGH_THRESHOLD:\n",
        "          return 'â˜ '\n",
        "     elif r2 == R2_EXCEEDINGLY_HIGH_THRESHOLD:\n",
        "          return 'ðŸš«'\n",
        "     else:\n",
        "          return 'ðŸ›‘'\n",
        "\n",
        "def categorize_mase(mase: float) -> str:\n",
        "     '''Categorize MASE into 7 categories'''\n",
        "     if mase == PERFECT_THRESHOLD:\n",
        "          return PERFECT\n",
        "     elif mase <= BETTER_THAN_NAIVE_LOW:\n",
        "          return VERY_ACCEPTABLE\n",
        "     elif mase <= BETTER_THAN_NAIVE_MED:\n",
        "          return ACCEPTABLE\n",
        "     elif mase <= BETTER_THAN_NAIVE_HIGH:\n",
        "          return MODERATE\n",
        "     elif mase < NAIVE_THRESHOLD:\n",
        "          return HIGH\n",
        "     elif mase == NAIVE_THRESHOLD:\n",
        "          return EQUIVALENT_TO_NAIVE_MODEL\n",
        "     else:\n",
        "          return WORSE_THAN_NAIVE_MODEL\n",
        "\n",
        "def emoji_categorize_mase(mase: float) -> str:\n",
        "     '''Categorize MASE into 7 emoji categories'''\n",
        "     if mase == PERFECT_THRESHOLD:\n",
        "          return 'ðŸ’¯'\n",
        "     elif mase <= BETTER_THAN_NAIVE_LOW:\n",
        "          return 'ðŸ‘Œ'\n",
        "     elif mase <= BETTER_THAN_NAIVE_MED:\n",
        "          return 'âœ”ï¸'\n",
        "     elif mase <= BETTER_THAN_NAIVE_HIGH:\n",
        "          return 'â—'\n",
        "     elif mase < NAIVE_THRESHOLD:\n",
        "          return 'âŒ'\n",
        "     elif mase == NAIVE_THRESHOLD:\n",
        "          return 'âš–'\n",
        "     else:\n",
        "          return 'ðŸ¤¬'\n",
        "\n",
        "@catch_warning_decorator\n",
        "def display_metrics(test: pd.Series,\n",
        "                    pred: pd.Series,\n",
        "                    train: pd.Series,\n",
        "                    y_max: Union[int, float],\n",
        "                    y_min: Union[int, float]):\n",
        "    '''Display all the metrics in dataframe'''\n",
        "    R2_val = r2_score(test, pred)\n",
        "    MAE_val = mae(test, pred)\n",
        "    MSE_val = mse(test, pred)\n",
        "    RMSE_val = rmse(test, pred)\n",
        "    MASE_val = mase(test, pred, train)\n",
        "    MAPE_val = mape(test, pred)\n",
        "    sMAPE_val = smape(test, pred)\n",
        "    MBD_category, MBD_val = mbd(test, pred)\n",
        "    emoji_MBD_category = 'ðŸ“ˆ' if MBD_category == OVERESTIMATION else 'ðŸ“‰'\n",
        "    metric_dict = {\n",
        "        'Metric': [\n",
        "            R2,\n",
        "            MAE,\n",
        "            MSE,\n",
        "            RMSE,\n",
        "            MASE,\n",
        "            MAPE,\n",
        "            SMAPE,\n",
        "            MBD\n",
        "        ],\n",
        "        'Value': [\n",
        "            R2_val,\n",
        "            MAE_val,\n",
        "            MSE_val,\n",
        "            RMSE_val,\n",
        "            MASE_val,\n",
        "            MAPE_val,\n",
        "            sMAPE_val,\n",
        "            MBD_val\n",
        "        ],\n",
        "        'Category': [\n",
        "            None if np.isnan(R2_val) else categorize_r2(R2_val),\n",
        "            None if np.isnan(MAE_val) else categorize_metrics(MAE_val, y_min, y_max),\n",
        "            None if np.isnan(MSE_val) else categorize_metrics(MSE_val, y_min, y_max),\n",
        "            None if np.isnan(RMSE_val) else categorize_metrics(RMSE_val, y_min, y_max),\n",
        "            None if np.isnan(MASE_val) else categorize_mase(MASE_val),\n",
        "            None if np.isnan(MAPE_val) else categorize_pe(MAPE_val),\n",
        "            None if np.isnan(sMAPE_val) else categorize_pe(sMAPE_val),\n",
        "            None if np.isnan(MBD_val) else f'{categorize_pe(abs(MBD_val))} {MBD_category}'\n",
        "        ],\n",
        "        'Emoji Category': [\n",
        "            'ðŸ™…â€â™‚ï¸' if np.isnan(R2_val) else emoji_categorize_r2(R2_val),\n",
        "            'ðŸ™…â€â™‚ï¸' if np.isnan(MAE_val) else emoji_categorize_metrics(MAE_val, y_min, y_max),\n",
        "            'ðŸ™…â€â™‚ï¸' if np.isnan(MSE_val) else emoji_categorize_metrics(MSE_val, y_min, y_max),\n",
        "            'ðŸ™…â€â™‚ï¸' if np.isnan(RMSE_val) else emoji_categorize_metrics(RMSE_val, y_min, y_max),\n",
        "            'ðŸ™…â€â™‚ï¸' if np.isnan(MASE_val) else emoji_categorize_mase(MASE_val),\n",
        "            'ðŸ™…â€â™‚ï¸' if np.isnan(MAPE_val) else emoji_categorize_pe(MAPE_val),\n",
        "            'ðŸ™…â€â™‚ï¸' if np.isnan(sMAPE_val) else emoji_categorize_pe(sMAPE_val),\n",
        "            'ðŸ™…â€â™‚ï¸' if np.isnan(MBD_val) else f'{emoji_categorize_pe(abs(MBD_val))}{emoji_MBD_category}'\n",
        "        ]\n",
        "    }\n",
        "    df = pd.DataFrame.from_dict(metric_dict)\n",
        "    display(df)\n",
        "\n",
        "def display_forecast_plotly(train: pd.Series,\n",
        "                            test: pd.Series,\n",
        "                            pred: pd.Series):\n",
        "    '''Visualization using Plotly'''\n",
        "    fig = go.Figure()\n",
        "    # Plotting training data\n",
        "    fig.add_trace(go.Scatter(x=train.index, y=train.values,\n",
        "                        mode='lines',\n",
        "                        name='Train'))\n",
        "    # Plotting test data\n",
        "    fig.add_trace(go.Scatter(x=test.index, y=test.values,\n",
        "                        mode='markers',\n",
        "                        name='Test',\n",
        "                        marker=dict(color='lightgreen')))\n",
        "    # Plotting prediction data\n",
        "    fig.add_trace(go.Scatter(x=pred.index, y=pred.values,\n",
        "                        mode='markers',\n",
        "                        name='Prediction',\n",
        "                        marker=dict(color='purple')))\n",
        "    # Show figure\n",
        "    fig.show()\n",
        "\n",
        "def repeated_pattern(x: int) -> int:\n",
        "    \"\"\"\n",
        "    Compute a repeating pattern for a given integer.\n",
        "\n",
        "    The function takes an integer input, computes its modulus with 5, and then adds 1.\n",
        "    The result is a number in the range [1, 5] which repeats for every consecutive block of 5 integers.\n",
        "\n",
        "    Parameters:\n",
        "    - x (int): Input integer.\n",
        "\n",
        "    Returns:\n",
        "    - int: Integer in the range [1, 5] representing the repeated pattern.\n",
        "    \"\"\"\n",
        "    return (x % 5) + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "    <summary>\n",
        "    <strong>Metrics Exploration Graph (click to expand/collapse)</strong>\n",
        "    </summary>\n",
        "\n",
        "![metrics exploration](https://raw.githubusercontent.com/ranggakd/DAIly/main/ideas/regression_forecasting_metrics/assets/metrics_exploration.png)\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/mercury+json": {
              "allow_download": true,
              "code_uid": "App.0.40.25.1-rand36160b0f",
              "continuous_update": true,
              "description": "Dashboard of experimental result across different regression/forecasting metrics",
              "full_screen": true,
              "model_id": "mercury-app",
              "notify": "{}",
              "output": "app",
              "schedule": "",
              "show_code": false,
              "show_prompt": false,
              "show_sidebar": true,
              "static_notebook": false,
              "stop_on_error": true,
              "title": "Regression-Forecasting Metric DashboardðŸ“ˆ",
              "widget": "App"
            },
            "text/html": [
              "<h3>Mercury Application</h3><small>This output won't appear in the web app.</small>"
            ],
            "text/plain": [
              "mercury.App"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "app = mr.App(\n",
        "    title='Regression-Forecasting Metric Dashboard',\n",
        "    description='Dashboard of experimental result across different regression/forecasting metrics',\n",
        "    stop_on_error=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# all syntetics dataset\n",
        "def numeric_widget(num: float, label: str) -> mr.Numeric:\n",
        "    return mr.Numeric(value=num, min=num, max=num+1, label=label, disabled=True)\n",
        "\n",
        "def cos_dataset(days: int, scale_factor: float = 1, const: float = 0) -> pd.Series:\n",
        "    date_range = pd.date_range(datetime(1970, 1, 1), periods=days)\n",
        "    x = np.linspace(0, 2 * np.pi, days)\n",
        "    y = np.cos(x) * scale_factor + const\n",
        "    cos_df = pd.DataFrame({'Value': y})\n",
        "    cos_df.set_index(date_range, inplace=True)\n",
        "    _ = numeric_widget(days, 'X')\n",
        "    if scale_factor != 1:\n",
        "        _ = numeric_widget(scale_factor, 'Scale Factor')\n",
        "    if const != 0:\n",
        "        _ = numeric_widget(const, 'Constant')\n",
        "    return cos_df['Value']\n",
        "\n",
        "def sin_dataset(days: int, \n",
        "                scale_factor: float = 1, \n",
        "                const: float = 0,\n",
        "                period: float = 1,\n",
        "                amplitude: float = 2) -> pd.Series:\n",
        "    date_range = pd.date_range(datetime(1970, 1, 1), periods=days)\n",
        "    x = np.linspace(0, amplitude * np.pi, days)\n",
        "    y = np.sin(period * x) * scale_factor + const\n",
        "    sin_df = pd.DataFrame({'Value': y})\n",
        "    sin_df.set_index(date_range, inplace=True)\n",
        "    _ = numeric_widget(days, 'X')\n",
        "    if scale_factor != 1:\n",
        "        _ = numeric_widget(scale_factor, 'Scale Factor')\n",
        "    if const != 0:\n",
        "        _ = numeric_widget(const, 'Constant')\n",
        "    if period != 1:\n",
        "        _ = numeric_widget(period, 'Period')\n",
        "    if amplitude != 2:\n",
        "        _ = numeric_widget(amplitude, 'Amplitude')\n",
        "    return sin_df['Value']\n",
        "\n",
        "def plot_linear_dataset(days: int = 100, scale_factor: float = 5, const: float = 2):\n",
        "    date_range = pd.date_range(datetime(1970, 1, 1), periods=days)\n",
        "    x = np.linspace(0, 2 * np.pi, days)\n",
        "    y_linear_inc = scale_factor * x + const\n",
        "    y_linear_dec = (-scale_factor) * x + const\n",
        "    plt.plot(x, y_linear_inc, label='Increasing Linear')\n",
        "    plt.plot(x, y_linear_dec, label='Decreasing Linear')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def linear_dataset(days: int, scale_factor: float = 5, const: float = 2) -> pd.Series:\n",
        "    date_range = pd.date_range(datetime(1970, 1, 1), periods=days)\n",
        "    x = np.linspace(0, 2 * np.pi, days)\n",
        "    y = scale_factor * x + const\n",
        "    linear_df = pd.DataFrame({'Value': y})\n",
        "    linear_df.set_index(date_range, inplace=True)\n",
        "    _ = numeric_widget(days, 'X')\n",
        "    _ = numeric_widget(scale_factor, 'Scale Factor')\n",
        "    _ = numeric_widget(const, 'Constant')\n",
        "    return linear_df['Value']\n",
        "\n",
        "def plot_exp_dataset(days: int = 100, scale_factor: float = 2, coefficient: float = .5):\n",
        "    date_range = pd.date_range(datetime(1970, 1, 1), periods=days)\n",
        "    x = np.linspace(0, 2 * np.pi, days)\n",
        "    y_exp_growth = scale_factor * np.exp(coefficient * x)\n",
        "    y_exp_decay = scale_factor * np.exp(coefficient * (2 * np.pi - x))\n",
        "    plt.plot(x, y_exp_growth, label='Exponential Growth')\n",
        "    plt.plot(x, y_exp_decay, label='Exponential Decay')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def exp_dataset(days: int, \n",
        "                scale_factor: float = 2, \n",
        "                coefficient: float = .5, \n",
        "                is_decreased: bool = False) -> pd.Series:\n",
        "    date_range = pd.date_range(datetime(1970, 1, 1), periods=days)\n",
        "    x = np.linspace(0, 2 * np.pi, days)\n",
        "    if is_decreased:\n",
        "        y = scale_factor * np.exp(coefficient * (2 * np.pi - x))\n",
        "    else:\n",
        "        y = scale_factor * np.exp(coefficient * x)\n",
        "    exp_df = pd.DataFrame({'Value': y})\n",
        "    exp_df.set_index(date_range, inplace=True)\n",
        "    _ = numeric_widget(days, 'X')\n",
        "    _ = numeric_widget(scale_factor, 'Scale Factor')\n",
        "    _ = numeric_widget(coefficient, 'Coefficient')\n",
        "    return exp_df['Value']\n",
        "    \n",
        "def plot_quad_dataset(days: int = 100, scale_factor: float = 1, power: float = 2):\n",
        "    date_range = pd.date_range(datetime(1970, 1, 1), periods=days)\n",
        "    x = np.linspace(0, 2 * np.pi, days)\n",
        "    y_quad_inc = scale_factor * (x)**power\n",
        "    y_quad_dec = -scale_factor *(x)**power\n",
        "    plt.plot(x, y_quad_inc, label='Increasing Quadratic')\n",
        "    plt.plot(x, y_quad_dec, label='Decreasing Quadratic')\n",
        "    plt.legend()\n",
        "    plt.show()    \n",
        "\n",
        "def quad_dataset(days: int, scale_factor: float = 1, power: float = 2) -> pd.Series:\n",
        "    date_range = pd.date_range(datetime(1970, 1, 1), periods=days)\n",
        "    x = np.linspace(0, 2 * np.pi, days)\n",
        "    y = scale_factor * (x)**power\n",
        "    quad_df = pd.DataFrame({'Value': y})\n",
        "    quad_df.set_index(date_range, inplace=True)\n",
        "    _ = numeric_widget(days, 'X')\n",
        "    _ = numeric_widget(scale_factor, 'Scale Factor')\n",
        "    _ = numeric_widget(power, 'Power')\n",
        "    return quad_df['Value']\n",
        "\n",
        "def plot_log_dataset(days: int = 100, \n",
        "                     scale_factor: float = 5, \n",
        "                     const: float = 10, \n",
        "                     hshift: float = 1):\n",
        "    date_range = pd.date_range(datetime(1970, 1, 1), periods=days)\n",
        "    x = np.linspace(0, 2 * np.pi, days)\n",
        "    y_log_inc = const + scale_factor * np.log(x + hshift)\n",
        "    y_log_dec = const - scale_factor * np.log(x + hshift)\n",
        "    plt.plot(x, y_log_inc, label='Increasing Logarithmic')\n",
        "    plt.plot(x, y_log_dec, label='Decreasing Logarithmic')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def log_dataset(days: int, \n",
        "                scale_factor: float = 5, \n",
        "                const: float = 10, \n",
        "                hshift: float = 1) -> pd.Series:\n",
        "    date_range = pd.date_range(datetime(1970, 1, 1), periods=days)\n",
        "    x = np.linspace(0, 2 * np.pi, days)\n",
        "    y = const + scale_factor * np.log(x + hshift)\n",
        "    log_df = pd.DataFrame({'Value': y})\n",
        "    log_df.set_index(date_range, inplace=True)\n",
        "    _ = numeric_widget(days, 'X')\n",
        "    _ = numeric_widget(scale_factor, 'Scale Factor')\n",
        "    _ = numeric_widget(const, 'Constant')\n",
        "    _ = numeric_widget(hshift, 'Horizontal Shift')\n",
        "    return log_df['Value']\n",
        "\n",
        "def plot_sigm_dataset(days: int = 100, \n",
        "                      scale_factor: float = 1, \n",
        "                      const: float = 1,\n",
        "                      upper_asymptote: float = 10,\n",
        "                      power_const: float = 5):\n",
        "    date_range = pd.date_range(datetime(1970, 1, 1), periods=days)\n",
        "    x = np.linspace(0, 2 * np.pi, days)\n",
        "    y_sigm_inc = scale_factor * upper_asymptote / (const + np.exp(-x + power_const))\n",
        "    y_sigm_dec = -scale_factor * upper_asymptote / (const + np.exp(-x + power_const))\n",
        "    plt.plot(x, y_sigm_inc, label='Increasing Sigmoidal')\n",
        "    plt.plot(x, y_sigm_dec, label='Decreasing Sigmoidal')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def sigm_dataset(days: int, \n",
        "                 scale_factor: float = 1, \n",
        "                 const: float = 1,\n",
        "                 upper_asymptote: float = 10,\n",
        "                 power_const: float = 5) -> pd.Series:\n",
        "    date_range = pd.date_range(datetime(1970, 1, 1), periods=days)\n",
        "    x = np.linspace(0, 2 * np.pi, days)\n",
        "    y = scale_factor * upper_asymptote / (const + np.exp(-x + power_const))\n",
        "    sigm_df = pd.DataFrame({'Value': y})\n",
        "    sigm_df.set_index(date_range, inplace=True)\n",
        "    _ = numeric_widget(days, 'X')\n",
        "    _ = numeric_widget(scale_factor, 'Scale Factor')\n",
        "    _ = numeric_widget(const, 'Constant')\n",
        "    _ = numeric_widget(upper_asymptote, 'Upper Asymptote')\n",
        "    _ = numeric_widget(power_const, 'Power Constant')\n",
        "    return sigm_df['Value']\n",
        "\n",
        "def outliers_dataset(days: int = 100, \n",
        "                     scale_factor: float = 1, \n",
        "                     const: float = 0,\n",
        "                     period: float = 1,\n",
        "                     amplitude: float = 4) -> pd.Series:\n",
        "    date_range = pd.date_range(datetime(1970, 1, 1), periods=days)\n",
        "    x = np.linspace(0, amplitude * np.pi, days)\n",
        "    y = np.sin(period * x) * scale_factor + const\n",
        "    y_extreme = np.where(np.abs(y) > .99, 1000 * y, y)\n",
        "    outliers_df = pd.DataFrame({'Value': y_extreme})\n",
        "    outliers_df.set_index(date_range, inplace=True)\n",
        "    _ = numeric_widget(days, 'X')\n",
        "    if scale_factor != 1:\n",
        "        _ = numeric_widget(scale_factor, 'Scale Factor')\n",
        "    if const != 0:\n",
        "        _ = numeric_widget(const, 'Constant')\n",
        "    if period != 1:\n",
        "        _ = numeric_widget(period, 'Period')\n",
        "    if amplitude != 2:\n",
        "        _ = numeric_widget(amplitude, 'Amplitude')\n",
        "    return outliers_df['Value']\n",
        "\n",
        "def rep_dataset(days: 100) -> pd.Series:\n",
        "    date_range = pd.date_range(datetime(1970, 1, 1), periods=days)\n",
        "    x = np.arange(0, days)\n",
        "    y = np.array([repeated_pattern(i) for i in x])\n",
        "    df = pd.DataFrame({'Value': y})\n",
        "    df.set_index(date_range, inplace=True)\n",
        "    return df['Value']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ts1_cos(model1: str, model2: str):\n",
        "    days = 100_000\n",
        "    series = cos_dataset(days=days)\n",
        "    # autoreg\n",
        "    train_size = len(series)-1\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def ts1_sin(model1: str, model2: str):\n",
        "    days = 100_000\n",
        "    series = sin_dataset(days=days)\n",
        "    # autoreg\n",
        "    train_size = len(series)-1\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def ts2_cos(model1: str, model2: str):\n",
        "    days = 100_000\n",
        "    series = cos_dataset(days=days)\n",
        "    # autoreg\n",
        "    train_size = len(series)-2\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def ts2_sin(model1: str, model2: str):\n",
        "    days = 100_000\n",
        "    series = sin_dataset(days=days)\n",
        "    # autoreg\n",
        "    train_size = len(series)-2\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def tm_cos(model1: str, model2: str):\n",
        "    days = 100_000\n",
        "    series = cos_dataset(days=days)\n",
        "    # autoreg\n",
        "    train_size = len(series)-50\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def tm_sin(model1: str, model2: str):\n",
        "    days = 100_000\n",
        "    series = sin_dataset(days=days)\n",
        "    # autoreg\n",
        "    train_size = len(series)-50\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def tl_cos(model1: str, model2: str):\n",
        "    days = 100_000\n",
        "    series = cos_dataset(days=days)\n",
        "    # autoreg\n",
        "    train_size = len(series)-10_000\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def tl_sin(model1: str, model2: str):\n",
        "    days = 100_000\n",
        "    series = sin_dataset(days=days)\n",
        "    # autoreg\n",
        "    train_size = len(series)-10_000\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def nnz_cos(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = 10\n",
        "    const = 1\n",
        "    series = cos_dataset(days=days, scale_factor=scale_factor, const=const)\n",
        "    mr.Markdown(f'is the dataset contains zero: {contains_zero(series)}')\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def nnz_sin(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = 10\n",
        "    const = 1\n",
        "    series = sin_dataset(days=days, scale_factor=scale_factor, const=const)\n",
        "    mr.Markdown(f'is the dataset contains zero: {contains_zero(series)}')\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def nrn_cos(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = 10\n",
        "    series = cos_dataset(days=days, scale_factor=scale_factor).astype(int)\n",
        "    mr.Markdown(f'is the dataset contains zero: {contains_zero(series)}')\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def nrn_sin(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = 10\n",
        "    series = sin_dataset(days=days, scale_factor=scale_factor).astype(int)\n",
        "    mr.Markdown(f'is the dataset contains zero: {contains_zero(series)}')\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def nnn_cos(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = 10\n",
        "    const = -11\n",
        "    series = cos_dataset(days=days, scale_factor=scale_factor, const=const)\n",
        "    mr.Markdown(f'is the dataset contains non-negative: {contains_non_negative(series)}')\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def nnn_sin(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = 10\n",
        "    const = -11\n",
        "    series = sin_dataset(days=days, scale_factor=scale_factor, const=const)\n",
        "    mr.Markdown(f'is the dataset contains non-negative: {contains_non_negative(series)}')\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def npn_cos(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = 10\n",
        "    const = 11\n",
        "    series = cos_dataset(days=days, scale_factor=scale_factor, const=const)\n",
        "    mr.Markdown(f'is the dataset contains non-positive: {contains_non_positive(series)}')\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def npn_sin(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = 10\n",
        "    const = 11\n",
        "    series = sin_dataset(days=days, scale_factor=scale_factor, const=const)\n",
        "    mr.Markdown(f'is the dataset contains non-positive: {contains_non_positive(series)}')\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def nvs_cos(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = 1e-6\n",
        "    series = cos_dataset(days=days, scale_factor=scale_factor)\n",
        "    mr.Markdown(f'Min: {series.min()}')\n",
        "    mr.Markdown(f'Max: {series.max()}')\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def nvs_sin(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = 1e-6\n",
        "    series = sin_dataset(days=days, scale_factor=scale_factor)\n",
        "    mr.Markdown(f'Min: {series.min()}')\n",
        "    mr.Markdown(f'Max: {series.max()}')\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def nvl_cos(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = 1e11\n",
        "    series = cos_dataset(days=days, scale_factor=scale_factor)\n",
        "    mr.Markdown(f'Min: {series.min()}')\n",
        "    mr.Markdown(f'Max: {series.max()}')\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def nvl_sin(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = 1e11\n",
        "    series = sin_dataset(days=days, scale_factor=scale_factor)\n",
        "    mr.Markdown(f'Min: {series.min()}')\n",
        "    mr.Markdown(f'Max: {series.max()}')\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ms_cos(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = 100\n",
        "    const = 200\n",
        "    series = cos_dataset(days=days, scale_factor=scale_factor, const=const)\n",
        "    mr.Markdown(f'Min: {series.min()}')\n",
        "    mr.Markdown(f'Max: {series.max()}')\n",
        "    _ = series.plot.hist()\n",
        "    plt.show()\n",
        "    # offset 1%\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset 10%\n",
        "    predictions = offsetmodel_predict(series, train_size, .1)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def ms_sin(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = 100\n",
        "    const = 200\n",
        "    series = sin_dataset(days=days, scale_factor=scale_factor, const=const)\n",
        "    mr.Markdown(f'Min: {series.min()}')\n",
        "    mr.Markdown(f'Max: {series.max()}')\n",
        "    _ = series.plot.hist()\n",
        "    plt.show()\n",
        "    # offset 1%\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset 10%\n",
        "    predictions = offsetmodel_predict(series, train_size, .1)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def md_cos(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = 10\n",
        "    const = 21\n",
        "    series = cos_dataset(days=days, scale_factor=scale_factor, const=const)\n",
        "    mr.Markdown(f'Min: {series.min()}')\n",
        "    mr.Markdown(f'Max: {series.max()}')\n",
        "    _ = series.plot.hist()\n",
        "    plt.show()\n",
        "    # offset 500%\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = offsetmodel_predict(series, train_size, 5)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset 5000%\n",
        "    predictions = offsetmodel_predict(series, train_size, 50)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def md_sin(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = 10\n",
        "    const = 21\n",
        "    series = sin_dataset(days=days, scale_factor=scale_factor, const=const)\n",
        "    mr.Markdown(f'Min: {series.min()}')\n",
        "    mr.Markdown(f'Max: {series.max()}')\n",
        "    _ = series.plot.hist()\n",
        "    plt.show()\n",
        "    # offset 500%\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = offsetmodel_predict(series, train_size, 5)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset 5000%\n",
        "    predictions = offsetmodel_predict(series, train_size, 50)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tl_inc(model1: str, model2: str):\n",
        "    days = 100\n",
        "    series = linear_dataset(days=days)\n",
        "    plot_linear_dataset()\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def tl_dec(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = -5\n",
        "    series = linear_dataset(days=days, scale_factor=scale_factor)\n",
        "    plot_linear_dataset()\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def texp_inc(model1: str, model2: str):\n",
        "    days = 100\n",
        "    series = exp_dataset(days=days)\n",
        "    plot_exp_dataset()\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def texp_dec(model1: str, model2: str):\n",
        "    days = 100\n",
        "    series = exp_dataset(days=days, is_decreased=True)\n",
        "    plot_exp_dataset()\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def tq_inc(model1: str, model2: str):\n",
        "    days = 100\n",
        "    series = quad_dataset(days=days)\n",
        "    plot_quad_dataset()\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def tq_dec(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = -1\n",
        "    series = quad_dataset(days=days, scale_factor=scale_factor)\n",
        "    plot_quad_dataset()\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def tlog_inc(model1: str, model2: str):\n",
        "    days = 100\n",
        "    series = log_dataset(days=days)\n",
        "    plot_log_dataset()\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def tlog_dec(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = -5\n",
        "    series = log_dataset(days=days, scale_factor=scale_factor)\n",
        "    plot_log_dataset()\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def tsigm_inc(model1: str, model2: str):\n",
        "    days = 100\n",
        "    series = sigm_dataset(days=days)\n",
        "    plot_sigm_dataset()\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def tsigm_dec(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = -1\n",
        "    series = sigm_dataset(days=days, scale_factor=scale_factor)\n",
        "    plot_sigm_dataset()\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def tseason(model1: str, model2: str):\n",
        "    days = 365\n",
        "    scale_factor = 20\n",
        "    period = 4\n",
        "    series = sin_dataset(days=days, scale_factor=scale_factor, period=period)\n",
        "    date_range = pd.date_range(datetime(1970, 1, 1), periods=days)\n",
        "    plt.plot(date_range, series)\n",
        "    plt.scatter(date_range, series, color='green')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.title('Yearly Temperature Variation')\n",
        "    plt.show()\n",
        "    # autoreg\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def toutlier(model1: str, model2: str):\n",
        "    days = 100\n",
        "    series = outliers_dataset(days=days)\n",
        "    date_range = pd.date_range(datetime(1970, 1, 1), periods=days)\n",
        "    plt.plot(date_range, series)\n",
        "    plt.scatter(date_range, series, color='green')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.title('Piecewise function with extremes')\n",
        "    plt.show()\n",
        "    # autoreg\n",
        "    train_size = len(series)-40\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def trep(model1: str, model2: str):\n",
        "    days = 100\n",
        "    series = rep_dataset(days=days)\n",
        "    date_range = pd.date_range(datetime(1970, 1, 1), periods=days)\n",
        "    plt.plot(date_range, series)\n",
        "    plt.scatter(date_range, series, color='green')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.title('Repeated Pattern')\n",
        "    plt.show()\n",
        "    # autoreg\n",
        "    train_size = len(series)-40\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = autoreg_predict(train, test)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def eover_cos(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = 10\n",
        "    series = cos_dataset(days=days, scale_factor=scale_factor)\n",
        "    # offset 1%\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = offsetmodel_predict(series, train_size)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset 10%\n",
        "    predictions = offsetmodel_predict(series, train_size, .1)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def eunder_cos(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = 10\n",
        "    series = cos_dataset(days=days, scale_factor=scale_factor)\n",
        "    # offset 1%\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = negoffsetmodel_predict(series, train_size)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset 10%\n",
        "    predictions = negoffsetmodel_predict(series, train_size, .1)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "\n",
        "def erandom_cos(model1: str, model2: str):\n",
        "    days = 100\n",
        "    scale_factor = 10\n",
        "    series = cos_dataset(days=days, scale_factor=scale_factor)\n",
        "    # offset 1%\n",
        "    train_size = len(series)-30\n",
        "    train, test  = series[:train_size], series[train_size:]\n",
        "    predictions = randomoffsetmodel_predict(series, train_size)\n",
        "    y_max, y_min = train.max(), train.min()\n",
        "    mr.Markdown(f'**{model1}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n",
        "    # offset 10%\n",
        "    predictions = randomoffsetmodel_predict(series, train_size, .1)\n",
        "    mr.Markdown(f'**{model2}**')\n",
        "    display_metrics(test, predictions, train, y_max, y_min)\n",
        "    display_forecast_plotly(train, test, predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/mercury+json": {
              "code_uid": "Note.0.40.16.2-rand6a48575e",
              "model_id": "Note.0.40.16.2-rand6a48575e",
              "value": "---",
              "widget": "Note"
            },
            "text/markdown": [
              "---"
            ],
            "text/plain": [
              "mercury.Note"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/mercury+json": {
              "choices": [
                "Test Size",
                "Number Nature",
                "Magnitude",
                "Data Distribution and Patterns",
                "Nature of Errors"
              ],
              "code_uid": "Select.0.40.16.11.based-rand2717ffbe",
              "disabled": false,
              "hidden": false,
              "label": "Based on",
              "model_id": "17385731343b4896a7804e6ad956ecb8",
              "url_key": "based",
              "value": "Test Size",
              "widget": "Select"
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17385731343b4896a7804e6ad956ecb8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "mercury.Select"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "## Based on Test Size"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# based on branching\n",
        "mr.Note(text='---')\n",
        "based_on_mapping = {\n",
        "    'Test Size': 'Based on Test Size',\n",
        "    'Number Nature': 'Based on Number Nature',\n",
        "    'Magnitude': 'Based on Magnitude',\n",
        "    'Data Distribution and Patterns': 'Based on Data Distribution and Patterns',\n",
        "    'Nature of Errors': 'Based on Nature of Errors'\n",
        "}\n",
        "based_on_choices = list(based_on_mapping.keys())\n",
        "based_on_selection = mr.Select(\n",
        "    value=based_on_choices[0],\n",
        "    choices=based_on_choices,\n",
        "    label='Based on',\n",
        "    url_key='based'\n",
        ")\n",
        "mr.Markdown(f'## {based_on_mapping.get(based_on_selection.value)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/mercury+json": {
              "choices": [
                "Small (1)",
                "Small (>1)",
                "Mid",
                "Large"
              ],
              "code_uid": "Select.0.40.16.38.var-randfeb8ea1a",
              "disabled": false,
              "hidden": false,
              "label": "Variant",
              "model_id": "e23210167da64ae6888aba0a6ebab9b1",
              "url_key": "var",
              "value": "Small (1)",
              "widget": "Select"
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e23210167da64ae6888aba0a6ebab9b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "mercury.Select"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "### Small (1)"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Few data points might cause magnified errors in some metrics. (e.g., a test size of just 1 data point)"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# variant branching\n",
        "variant_mapping = {\n",
        "    'Test Size': {\n",
        "        'Small (1)': 'Few data points might cause magnified errors in some metrics. (e.g., a test size of just 1 data point)',\n",
        "        'Small (>1)': 'Few data points might cause magnified errors in some metrics. (e.g., a test size of 2 data points)',\n",
        "        'Mid': 'A moderate amount of data points. (e.g., test size of 50 data points)',\n",
        "        'Large': 'Many data points which can sometimes mask large individual errors. (e.g., test size of 10,000 data points)'\n",
        "    },\n",
        "    'Number Nature': {\n",
        "        'Non-zero Real Numbers': 'Standard scenario. (e.g., -5 and 7)',\n",
        "        'Real Numbers with Zeros': 'Important for some metrics which cannot handle zeros. (e.g., 0 and 7)',\n",
        "        'Negative Numbers Only': 'Metrics could behave differently when dealing with solely negative numbers. (e.g., -5 and -7)',\n",
        "        'Positive Numbers Only': 'Standard scenario. (e.g., 5 and 10)',\n",
        "        'Very Small Numbers': 'Close to zero but not zero; can test for amplification of error. (e.g., 0.000001 and 0.0001)',\n",
        "        'Very Large Numbers': 'Tests for potential overflow or underflow issues in metric calculation. (e.g., 10^10 and 10^11)'\n",
        "    },\n",
        "    'Magnitude': {\n",
        "        'Same Magnitude for $y$ and $\\hat{y}$': 'Tests the performance when predictions and true values are on the same scale. (e.g., 100 and 105)',\n",
        "        'Different Magnitude for $y$ and $\\hat{y}$': 'Investigating how metrics react when there is a noticeable scale difference between true and predicted values. (e.g., 1 vs 1000)'\n",
        "    },\n",
        "    'Data Distribution and Patterns': {\n",
        "        'Linear Trend': 'Examining cases where there is a consistent increase or decrease in data, indicating a linear trend',\n",
        "        'Exponential Growth / Decay': 'Examining cases where there is a consistent increase or decrease in data, indicating a exponential growth / decay',\n",
        "        'Quadratic Trend': 'Examining cases where there is a consistent increase or decrease in data, indicating a quadratic trend',\n",
        "        'Logarithmic Trend': 'Examining cases where there is a consistent increase or decrease in data, indicating a logarithmic trend',\n",
        "        'Sigmoidal/Logistic Trend': 'Examining cases where there is a consistent increase or decrease in data, indicating a sigmoidal/logistic trend',\n",
        "        'Seasonality': 'Occurrences of regular fluctuations in data. (e.g., sinusoidal data patterns or sales spikes during the holidays)',\n",
        "        'Outliers': 'Situations where there are extreme values that might disproportionately affect metrics. (e.g., series like 1, 2, 3, 1000, 5)',\n",
        "        'Repeated Patterns': 'Situations where certain patterns in the data repeat after regular intervals. (e.g., a daily temperature dataset that consistently peaks at midday and dips at midnight like 1, 2, 3, 1, 2, 3, 1, 2, 3....)'\n",
        "    },\n",
        "    'Nature of Errors': {\n",
        "        'Systematic Overestimation': 'When predictions are consistently higher than true values. (e.g., true: 1, 2, 3; predicted: 3, 4, 5)',\n",
        "        'Systematic Underestimation': 'When predictions are consistently lower than true values. (e.g., true: 3, 4, 5; predicted: 1, 2, 3)',\n",
        "        'Random Errors': 'Unpredictable error patterns where predictions sometimes overshoot and sometimes undershoot the true values and none of the predicted values exactly match the true values. (e.g., for a true sequence of 1, 2, 3, 4, 5, a prediction might be 2, 1.5, 4, 3.5, 5.5)'\n",
        "    }\n",
        "}\n",
        "variant_choices = list(variant_mapping[based_on_selection.value].keys())\n",
        "variant_selection = mr.Select(\n",
        "    value=variant_choices[0],\n",
        "    choices=variant_choices,\n",
        "    label='Variant',\n",
        "    url_key='var'\n",
        ")\n",
        "mr.Markdown(f'### {variant_selection.value}')\n",
        "mr.Markdown(f'{variant_mapping[based_on_selection.value][variant_selection.value]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/mercury+json": {
              "choices": [
                "$\\cos(x)$",
                "$\\sin(x)$"
              ],
              "code_uid": "Select.0.40.16.182.dataset-randf6a7ed08",
              "disabled": false,
              "hidden": false,
              "label": "Dataset",
              "model_id": "db6a767178a742f48c285d8d07692f72",
              "url_key": "dataset",
              "value": "$\\cos(x)$",
              "widget": "Select"
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db6a767178a742f48c285d8d07692f72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "mercury.Select"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "#### $\\cos(x)$"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# dataset branching\n",
        "dataset_mapping = {\n",
        "    'Test Size': {\n",
        "        'Small (1)':{\n",
        "            '$\\cos(x)$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): ts1_cos\n",
        "            },\n",
        "            '$\\sin(x)$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): ts1_sin\n",
        "            }\n",
        "        },\n",
        "        'Small (>1)':{\n",
        "            '$\\cos(x)$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): ts2_cos\n",
        "            },\n",
        "            '$\\sin(x)$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): ts2_sin\n",
        "            }\n",
        "        },\n",
        "        'Mid':{\n",
        "            '$\\cos(x)$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): tm_cos\n",
        "            },\n",
        "            '$\\sin(x)$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): tm_sin\n",
        "            }\n",
        "        },\n",
        "        'Large':{\n",
        "            '$\\cos(x)$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): tl_cos\n",
        "            },\n",
        "            '$\\sin(x)$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): tl_sin\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    'Number Nature': {\n",
        "        'Non-zero Real Numbers':{\n",
        "            '$10 \\cdot \\cos(x) + 1$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): nnz_cos\n",
        "            },\n",
        "            '$10 \\cdot \\sin(x) + 1$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): nnz_sin\n",
        "            }\n",
        "        },\n",
        "        'Real Numbers with Zeros':{\n",
        "            'int $(10 \\cdot \\cos(x))$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): nrn_cos\n",
        "            },\n",
        "            'int $(10 \\cdot \\sin(x))$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): nrn_sin\n",
        "            }\n",
        "        },\n",
        "        'Negative Numbers Only':{\n",
        "            '$10 \\cdot \\cos(x) - 11$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): nnn_cos\n",
        "            },\n",
        "            '$10 \\cdot \\sin(x) - 11$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): nnn_sin\n",
        "            }\n",
        "        },\n",
        "        'Positive Numbers Only':{\n",
        "            '$10 \\cdot \\cos(x) + 11$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): npn_cos\n",
        "            },\n",
        "            '$10 \\cdot \\sin(x) + 11$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): npn_sin\n",
        "            }\n",
        "        },\n",
        "        'Very Small Numbers':{\n",
        "            '$1 \\cdot 10^{-6} \\cdot \\cos(x)$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): nvs_cos\n",
        "            },\n",
        "            '$1 \\cdot 10^{-6} \\cdot \\sin(x)$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): nvs_sin\n",
        "            }\n",
        "        },\n",
        "        'Very Large Numbers':{\n",
        "            '$1 \\cdot 10^{11} \\cdot \\cos(x)$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): nvl_cos\n",
        "            },\n",
        "            '$1 \\cdot 10^{11} \\cdot \\sin(x)$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): nvl_sin\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    'Magnitude': {\n",
        "        'Same Magnitude for $y$ and $\\hat{y}$':{\n",
        "            '$100 \\cdot \\cos(x) + 200$':{\n",
        "                ('OffsetModel 1%', 'OffsetModel 10%'): ms_cos\n",
        "            },\n",
        "            '$100 \\cdot \\sin(x) + 200$':{\n",
        "                ('OffsetModel 1%', 'OffsetModel 10%'): ms_sin\n",
        "            }\n",
        "        },\n",
        "        'Different Magnitude for $y$ and $\\hat{y}$':{\n",
        "            '$10 \\cdot \\cos(x) + 21$':{\n",
        "                ('OffsetModel 500%', 'OffsetModel 5000%'): md_cos\n",
        "            },\n",
        "            '$10 \\cdot \\sin(x) + 21$':{\n",
        "                ('OffsetModel 500%', 'OffsetModel 5000%'): md_sin\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    'Data Distribution and Patterns': {\n",
        "        'Linear Trend':{\n",
        "            '$5x + 2$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): tl_inc\n",
        "            },\n",
        "            '$-5x + 2$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): tl_dec\n",
        "            }\n",
        "        },\n",
        "        'Exponential Growth / Decay':{\n",
        "            '$2e^{0.5x}$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): texp_inc\n",
        "            },\n",
        "            '$2e^{0.5(2\\pi - x)}$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): texp_dec\n",
        "            }\n",
        "        },\n",
        "        'Quadratic Trend':{\n",
        "            '$x^2$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): tq_inc\n",
        "            },\n",
        "            '$-x^2$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): tq_dec\n",
        "            }\n",
        "        },\n",
        "        'Logarithmic Trend':{\n",
        "            '$10 + 5\\ln(x+1)$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): tlog_inc\n",
        "            },\n",
        "            '$10 - 5\\ln(x+1)$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): tlog_dec\n",
        "            }\n",
        "        },\n",
        "        'Sigmoidal/Logistic Trend':{\n",
        "            '${10 \\over 1 + e^{-x + 5}}$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): tsigm_inc\n",
        "            },\n",
        "            '$-{10 \\over 1 + e^{-x + 5}}$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): tsigm_dec\n",
        "            }\n",
        "        },\n",
        "        'Seasonality':{\n",
        "            '$20 \\cdot \\cos(4x) + 50$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): tseason\n",
        "            }\n",
        "        },\n",
        "        'Outliers':{\n",
        "            '$\\\\begin{cases} \\sin(x) & \\\\text{if } \\\\vert\\sin(x)\\\\vert \\leq 0.99 \\\\\\ 1000\\sin(x) & '\n",
        "            '\\\\text{if } \\\\vert\\sin(x)\\\\vert > 0.99 \\\\end{cases}$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): toutlier\n",
        "            }\n",
        "        },\n",
        "        'Repeated Patterns':{\n",
        "            '$(x \\mod 5) + 1$':{\n",
        "                ('AutoReg', 'OffsetModel 1%'): trep\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    'Nature of Errors': {\n",
        "        'Systematic Overestimation':{\n",
        "            '$10 \\cdot \\cos(x)$':{\n",
        "                ('OffsetModel 1%', 'OffsetModel 10%'): eover_cos\n",
        "            }\n",
        "        },\n",
        "        'Systematic Underestimation':{\n",
        "            '$10 \\cdot \\cos(x)$':{\n",
        "                ('OffsetModel 1%', 'OffsetModel 10%'): eunder_cos\n",
        "            }\n",
        "        },\n",
        "        'Random Errors':{\n",
        "            '$10 \\cdot \\cos(x)$':{\n",
        "                ('OffsetModel 1%', 'OffsetModel 10%'): erandom_cos\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "dataset_choices = list(dataset_mapping[based_on_selection.value][variant_selection.value].keys())\n",
        "dataset_selection = mr.Select(\n",
        "    value=dataset_choices[0],\n",
        "    choices=dataset_choices,\n",
        "    label='Dataset',\n",
        "    url_key='dataset'\n",
        ")\n",
        "mr.Markdown(f'#### {dataset_selection.value}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model branching\n",
        "m = dataset_mapping[based_on_selection.value][variant_selection.value][dataset_selection.value]\n",
        "for model_tuple, exp in m.items(): exp(*model_tuple)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "    <summary>\n",
        "    <strong>Summary Tables (click to expand/collapse)</strong>\n",
        "    </summary>\n",
        "\n",
        "<br>\n",
        "\n",
        "<details>\n",
        "    <summary>\n",
        "    <strong>User-Defined Boundaries (click to expand/collapse)</strong>\n",
        "    </summary>\n",
        "\n",
        "> **Disclaimer:** These boundaries are user-defined. They may vary based on different context.\n",
        "\n",
        "#### Standard Error Metrics (MAE, MSE, RMSE) Categorization\n",
        "\n",
        "| Category           | Normalized Error Range  |\n",
        "|--------------------|-------------------------|\n",
        "| Perfect            | Exactly 0               |\n",
        "| Very Acceptable    | $0 < x \\leq 0.05$     |\n",
        "| Acceptable         | $0.05 < x \\leq 0.1$   |\n",
        "| Moderate           | $0.1 < x \\leq 0.2$    |\n",
        "| High               | $0.2 < x \\leq 0.3$    |\n",
        "| Very High          | $0.3 < x \\leq 1$    |\n",
        "| Exceedingly High   | $x > 1$             |\n",
        "\n",
        "#### Percentage Error (PE) Categorization\n",
        "\n",
        "| Category          | Error Magnitude (%) | Direction |\n",
        "|-------------------|-----------------------|-----------|\n",
        "| Perfect           | Exactly 0            | -         |\n",
        "| Very Acceptable   | $0 < x \\leq 5$    | Over/Under|\n",
        "| Acceptable        | $5 < x \\leq 10$   | Over/Under|\n",
        "| Moderate          | $10 < x \\leq 20$  | Over/Under|\n",
        "| High              | $20 < x \\leq 30$  | Over/Under|\n",
        "| Very High         | $30 < x \\leq 100$ | Over/Under|\n",
        "| Exceedingly High  | $x > 100$           | Over/Under|\n",
        "\n",
        "#### R2 Score Categorization\n",
        "\n",
        "| Category                           | R2 Value Range    |\n",
        "|------------------------------------|-------------------|\n",
        "| Perfect                            | Exactly 1         |\n",
        "| Very Acceptable                    | $0.95 \\leq x < 1$|\n",
        "| Acceptable                         | $0.9 \\leq x < 0.95$|\n",
        "| Moderate                           | $0.8 \\leq x < 0.9$|\n",
        "| High                               | $0.7 \\leq x < 0.8$|\n",
        "| Very High                          | $0.5 \\leq x < 0.7$|\n",
        "| Exceedingly High                   | $0 < x < 0.5$   |\n",
        "| Doesn't Explain Variability        | Exactly 0       |\n",
        "| Worse Than Simple Mean Model       | $x < 0$         |\n",
        "\n",
        "#### MASE Categorization\n",
        "\n",
        "| Category           | MASE Value Range  |\n",
        "|--------------------|-------------------|\n",
        "| Perfect            | Exactly 0         |\n",
        "| Very Acceptable    | $0 < x \\leq 0.1$|\n",
        "| Acceptable         | $0.1 < x \\leq 0.5$|\n",
        "| Moderate           | $0.5 < x \\leq 0.9$|\n",
        "| High               | $0.9 < x \\leq 1$|\n",
        "| Equivalent to Naive Model          | Exactly 1         |\n",
        "| Worse Than Naive Forecast Model | $x > 1$ |\n",
        "\n",
        "#### Severity Emojis\n",
        "\n",
        "| Metric | Emoji |\n",
        "|--------|-------|\n",
        "| Perfect | ðŸ’¯ |\n",
        "| Very Acceptable | ðŸ‘Œ |\n",
        "| Acceptable | âœ”ï¸ |\n",
        "| Moderate | â— |\n",
        "| High | âŒ |\n",
        "| Very High | ðŸ’€ |\n",
        "| Exceedingly High | â˜  |\n",
        "| Doesn't Explain Variability | ðŸš« |\n",
        "| Worse Than Simple Mean Model | ðŸ›‘ |\n",
        "| Equivalent to Naive Model | âš– |\n",
        "| Worse Than Naive Forecast Model | ðŸ¤¬ |\n",
        "\n",
        "#### Directional Emojis\n",
        "\n",
        "| Metric | Emoji |\n",
        "|--------|-------|\n",
        "| Overestimation | ðŸ“ˆ |\n",
        "| Underestimation | ðŸ“‰ |\n",
        "| Nan / None | ðŸ™…â€â™‚ï¸ |\n",
        "\n",
        "</details>\n",
        "\n",
        "<br>\n",
        "\n",
        "<details>\n",
        "    <summary>\n",
        "    <strong>Disclaimer:</strong> \n",
        "    </summary>\n",
        "\n",
        "> 1. Metrics are calculated using `sklearn.metrics`, with the exception of `MASE`, `sMAPE`, and `MBD`. Results may vary based on different implementations.\n",
        "> 2. The datasets for these metrics were synthesized using mathematical formulas like sine and cosine for controlled predictability.\n",
        "> 3. The controlled models used are `statsmodels.tsa.ar_model.AutoReg` and `OffsetModel`. \n",
        "> 4. `AutoReg` was chosen for its fundamental nature in *time series forecasting*, while `OffsetModel` mimics good performance by shifting test data positively (default by 1%).\n",
        "> 5. This experiment focuses on **forecasting problems**, highlighting that all forecasting problems are regressions, but not vice-versa.\n",
        "> 6. When using `MBD` with negative or mixed observed values, interpret results with caution. **The metric's sign** can be influenced by both **the bias direction** and **the sign of observed values**.\n",
        "> 7. This experiment is not intended to serve as a rule of thumb or a best practice. Instead, it offers a glimpse into how different metrics behave on controlled models and datasets to foster a deeper understanding.\n",
        "> 8. **Use insights from this exploration at your own risk.**\n",
        "\n",
        "</details>\n",
        "\n",
        "<br>\n",
        "\n",
        "| Based on | Variant | Dataset | Model | R2 | MAE | MSE | RMSE | MASE | MAPE | sMAPE | MBDev |\n",
        "|--|--|--|--|--|--|--|--|--|--|--|--|\n",
        "| Test Size | Small=1 | $\\cos(x)$ | AutoReg |ðŸ™…â€â™‚ï¸|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ¤¬|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| | | | OffsetModel |ðŸ™…â€â™‚ï¸|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ¤¬|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| | | $\\sin(x)$ | AutoReg |ðŸ™…â€â™‚ï¸|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ¤¬|â˜ |â˜ |â˜ ðŸ“‰|\n",
        "| | | | OffsetModel |ðŸ™…â€â™‚ï¸|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ¤¬|â˜ |â˜ |â˜ ðŸ“ˆ|\n",
        "| | Small=2 | $\\cos(x)$ | AutoReg |ðŸ›‘|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ¤¬|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| | | | OffsetModel |ðŸ›‘|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ¤¬|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| | | $\\sin(x)$ | AutoReg |ðŸ›‘|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ¤¬|â˜ |â˜ |â˜ ðŸ“‰|\n",
        "| | | | OffsetModel |ðŸ›‘|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ¤¬|â˜ |â˜ |â˜ ðŸ“ˆ|\n",
        "| | Mid | $\\cos(x)$ | AutoReg |ðŸ›‘|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ¤¬|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| | | | OffsetModel |ðŸ›‘|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ¤¬|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| | | $\\sin(x)$ | AutoReg |ðŸ›‘|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ¤¬|â˜ |ðŸ’€|â˜ ðŸ“‰|\n",
        "| | | | OffsetModel |ðŸ›‘|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ¤¬|â˜ |â˜ |â˜ ðŸ“ˆ|\n",
        "| | Large | $\\cos(x)$ | AutoReg |ðŸ›‘|â—|âœ”ï¸|âŒ|ðŸ¤¬|ðŸ‘Œ|âŒ|ðŸ’€ðŸ“ˆ|\n",
        "| | | | OffsetModel |â—|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ¤¬|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| | | $\\sin(x)$ | AutoReg |ðŸ›‘|âŒ|â—|âŒ|ðŸ¤¬|â˜ |ðŸ’€|â˜ ðŸ“‰|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ¤¬|â˜ |â—|â˜ ðŸ“ˆ|\n",
        "| Number Nature | Non-zero Real Numbers | $10 \\cdot \\cos(x) + 1$ | AutoReg |ðŸ›‘|â˜ |â˜ |â˜ |ðŸ¤¬|ðŸ‘Œ|â˜ |â˜ ðŸ“ˆ|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|â—|ðŸ‘Œ|âœ”ï¸|ðŸ‘ŒðŸ“ˆ|\n",
        "| | | $10 \\cdot \\sin(x) + 1$ | AutoReg |ðŸ›‘|ðŸ’€|â˜ |ðŸ’€|ðŸ¤¬|â—|ðŸ’€|â˜ ðŸ“‰|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|âœ”ï¸|ðŸ‘Œ|â—|ðŸ‘ŒðŸ“ˆ|\n",
        "| | Real Numbers | $\\text{int}(10 \\cdot \\cos(x))$ | AutoReg |ðŸ›‘|ðŸ’€|â˜ |â˜ |ðŸ¤¬|â˜ |â˜ |â˜ ðŸ“ˆ|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|â—|â˜ |âŒ|â˜ ðŸ“ˆ|\n",
        "| | | $\\text{int}(10 \\cdot \\sin(x))$ | AutoReg |ðŸ›‘|ðŸ’€|â˜ |ðŸ’€|ðŸ¤¬|â˜ |ðŸ’€|â˜ ðŸ“‰|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|âœ”ï¸|â˜ |â—|â˜ ðŸ“ˆ|\n",
        "| | Negative Numbers Only | $10 \\cdot \\cos(x) - 11$ | AutoReg |ðŸ›‘|â˜ |â˜ |â˜ |ðŸ¤¬|â—|â˜ |â˜ ðŸ“ˆ|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|â—|ðŸ‘Œ|âœ”ï¸|ðŸ‘ŒðŸ“ˆ|\n",
        "| | | $10 \\cdot \\sin(x) - 11$ | AutoReg |ðŸ›‘|ðŸ’€|â˜ |ðŸ’€|ðŸ¤¬|ðŸ‘Œ|ðŸ’€|ðŸ’€ðŸ“‰|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|âœ”ï¸|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| | Positive Numbers Only | $10 \\cdot \\cos(x) + 11$ | AutoReg |ðŸ›‘|â˜ |â˜ |â˜ |ðŸ¤¬|ðŸ‘Œ|ðŸ’€|â˜ ðŸ“ˆ|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|â—|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| | | $10 \\cdot \\sin(x) + 11$ | AutoReg |ðŸ›‘|ðŸ’€|â˜ |ðŸ’€|ðŸ¤¬|ðŸ‘Œ|ðŸ’€|ðŸ’€ðŸ“‰|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|âœ”ï¸|ðŸ‘Œ|âœ”ï¸|âœ”ï¸ðŸ“ˆ|\n",
        "| | Very Small Numbers | $1 \\times 10^{-6} \\cdot \\cos(x)$ | AutoReg |ðŸ›‘|â˜ |ðŸ‘Œ|â˜ |ðŸ¤¬|ðŸ‘Œ|â˜ |â˜ ðŸ“ˆ|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|â—|ðŸ‘Œ|â—|ðŸ‘ŒðŸ“ˆ|\n",
        "| | | $1 \\times 10^{-6} \\cdot \\sin(x)$ | AutoReg |ðŸ›‘|ðŸ’€|ðŸ‘Œ|ðŸ’€|ðŸ¤¬|â˜ |ðŸ’€|â˜ ðŸ“‰|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|âœ”ï¸|â˜ |â—|â˜ ðŸ“ˆ|\n",
        "| | Very Large Numbers | $1 \\times 10^{11} \\cdot \\cos(x)$ | AutoReg |ðŸ›‘|â˜ |â˜ |â˜ |ðŸ¤¬|ðŸ‘Œ|â˜ |â˜ ðŸ“ˆ|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|â˜ |ðŸ‘Œ|â—|ðŸ‘Œ|â—|ðŸ‘ŒðŸ“ˆ|\n",
        "| | | $1 \\times 10^{11} \\cdot \\sin(x)$ | AutoReg |ðŸ›‘|ðŸ’€|â˜ |ðŸ’€|ðŸ¤¬|â˜ |ðŸ’€|â˜ ðŸ“‰|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|â˜ |ðŸ‘Œ|âœ”ï¸|â˜ |â—|â˜ ðŸ“ˆ|\n",
        "| Magnitude | Same Magnitude for $y \\text{ and } \\hat{y}$ | $100 \\cdot \\cos(x) + 200$ | OffsetModel 1% |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|â—|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| | | | OffsetModel 10% |âŒ|âœ”ï¸|â˜ |âœ”ï¸|ðŸ¤¬|ðŸ‘Œ|âœ”ï¸|âœ”ï¸ðŸ“ˆ|\n",
        "|  |  | $100 \\cdot \\sin(x) + 200$ | OffsetModel 1% |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|âœ”ï¸|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| | | | OffsetModel 10% |ðŸ’€|â—|â˜ |â—|ðŸ¤¬|ðŸ‘Œ|â—|â—ðŸ“ˆ|\n",
        "| | Different Magnitude for $y \\text{ and } \\hat{y}$ | $10 \\cdot \\cos(x) + 21$ | OffsetModel 500% |ðŸ›‘|â˜ |â˜ |â˜ |ðŸ¤¬|ðŸ‘Œ|â˜ |â˜ ðŸ“ˆ|\n",
        "| | | | OffsetModel 5000% |ðŸ›‘|â˜ |â˜ |â˜ |ðŸ¤¬|ðŸ’€|â˜ |â˜ ðŸ“ˆ|\n",
        "| |  | $10 \\cdot \\sin(x) + 21$ | OffsetModel 500% |ðŸ›‘|â˜ |â˜ |â˜ |ðŸ¤¬|âœ”ï¸|â˜ |â˜ ðŸ“ˆ|\n",
        "| | | | OffsetModel 5000% |ðŸ›‘|â˜ |â˜ |â˜ |ðŸ¤¬|ðŸ’€|â˜ |â˜ ðŸ“ˆ|\n",
        "| Data Distribution and Patterns | Linear Trend | $5x + 2$ | AutoReg |ðŸ’¯|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|âŒ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| |  | $-5x + 2$ | AutoReg |ðŸ’¯|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“‰|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|âŒ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| | Exponential Growth/Decay | $2e^{0.5x}$ | AutoReg |ðŸ’¯|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“‰|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ¤¬|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| |  | $2e^{0.5(2\\pi - x)}$ | AutoReg |ðŸ’¯|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“‰|\n",
        "| | | | OffsetModel |âŒ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|â—|ðŸ‘Œ|â—|â—ðŸ“ˆ|\n",
        "| | Quadratic Trend | $x^2$ | AutoReg |ðŸ’¯|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ¤¬|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| |  | $-x^2$ | AutoReg |ðŸ’¯|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“‰|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ¤¬|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| | Logarithmic Trend | $10 + 5\\ln(x+1)$ | AutoReg |â—|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ¤¬|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| | | | OffsetModel |âœ”ï¸|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|â—|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| |  | $10 - 5\\ln(x+1)$ | AutoReg |â—|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ¤¬|ðŸ‘Œ|ðŸ’€|ðŸ’€ðŸ“‰|\n",
        "| | | | OffsetModel |âœ”ï¸|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|â—|ðŸ‘Œ|â—|âŒðŸ“ˆ|\n",
        "| | Sigmoidal/Logistic Trend | $\\frac{10}{1 + e^{-x + 5}}$ | AutoReg |ðŸ›‘|ðŸ’€|ðŸ’€|ðŸ’€|ðŸ¤¬|ðŸ‘Œ|â—|â—ðŸ“ˆ|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ¤¬|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| |  | $-\\frac{10}{1 + e^{-x + 5}}$ | AutoReg |ðŸ›‘|ðŸ’€|ðŸ’€|ðŸ’€|ðŸ¤¬|ðŸ‘Œ|â—|â—ðŸ“‰|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ¤¬|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| | Seasonality | $20 \\cdot \\sin(4x) + 50$ | AutoReg |ðŸ›‘|â—|â˜ |âŒ|ðŸ¤¬|ðŸ‘Œ|âŒ|â—ðŸ“‰|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|âœ”ï¸|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| | Outliers | ![outliers math func](https://raw.githubusercontent.com/ranggakd/DAIly/main/ideas/regression_forecasting_metrics/assets/outliers_formula_b70.png) | AutoReg |ðŸ›‘|â—|â˜ |â—|ðŸ¤¬|â˜ |â˜ |â˜ ðŸ“‰|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|âŒ|ðŸ‘Œ|âœ”ï¸|â˜ |â˜ |â˜ ðŸ“ˆ|\n",
        "| | Repeated Patterns | $(x \\mod 5) + 1$ | AutoReg |ðŸ›‘|ðŸ’€|ðŸ’€|ðŸ’€|â—|ðŸ‘Œ|ðŸ’€|ðŸ’€ðŸ“ˆ|\n",
        "| | | | OffsetModel |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘ŒðŸ“ˆ|\n",
        "| Nature of Errors | Systematic Overestimation | $10 \\cdot \\cos(x)$ | OffsetModel 1% |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|â—|ðŸ‘Œ|â—|ðŸ‘ŒðŸ“ˆ|\n",
        "| | | | OffsetModel 10% |âŒ|âœ”ï¸|â—|âœ”ï¸|ðŸ¤¬|ðŸ‘Œ|ðŸ’€|â—ðŸ“ˆ|\n",
        "| | Systematic Underestimation | $10 \\cdot \\cos(x)$ | NegOffsetModel 1% |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|â—|ðŸ‘Œ|â—|ðŸ‘ŒðŸ“‰|\n",
        "| | | | NegOffsetModel 10% |âŒ|âœ”ï¸|â—|â—|ðŸ¤¬|ðŸ‘Œ|ðŸ’€|â—ðŸ“‰|\n",
        "| | Random Errors | $10 \\cdot \\cos(x)$ | RandomOffsetModel 1% |ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|ðŸ‘Œ|â—|ðŸ‘Œ|â—|âœ”ï¸ðŸ“‰|\n",
        "| | | | RandomOffsetModel 10% |âŒ|âœ”ï¸|â—|âœ”ï¸|ðŸ¤¬|ðŸ‘Œ|ðŸ’€|âŒðŸ“ˆ|\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rf_metrics",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
