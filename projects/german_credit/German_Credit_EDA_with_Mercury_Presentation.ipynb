{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd09872e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#@markdown *Last running requirement version*\n",
    "\n",
    "# !python -V\n",
    "\n",
    "# uncomment line below if you are using Linux or Google Colab\n",
    "# !pip freeze | grep -w 'requests'\n",
    "# !pip freeze | grep -w 'pandas'\n",
    "# !pip freeze | grep -w 'mercury'\n",
    "# !pip freeze | grep -w 'ptitprince'\n",
    "# !pip freeze | grep -w 'scipy'\n",
    "# !pip freeze | grep -w 'matplotlib'\n",
    "# !pip freeze | grep -w 'category-encoders'\n",
    "# !pip freeze | grep -w 'scikit-learn'\n",
    "\n",
    "# uncomment line below if you are using Windows\n",
    "# !pip freeze | findstr /C:\"requests\"\n",
    "# !pip freeze | findstr /C:\"pandas\"\n",
    "# !pip freeze | findstr /C:\"mercury\"\n",
    "# !pip freeze | findstr /C:\"ptitprince\"\n",
    "# !pip freeze | findstr /C:\"scipy\"\n",
    "# !pip freeze | findstr /C:\"matplotlib\"\n",
    "# !pip freeze | findstr /C:\"category-encoders\"\n",
    "# !pip freeze | findstr /C:\"scikit-learn\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78f5cbf7",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07458cf9-e22b-47c8-8539-2e3d3c91dddb",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import mercury as mr\n",
    "import ptitprince as pt\n",
    "from scipy.io import arff\n",
    "import matplotlib.pyplot as plt\n",
    "from category_encoders import LeaveOneOutEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# xkcd-styled & humor sans font installed to give semi-sarcasm graph\n",
    "plt.xkcd()\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3db4316",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Constants and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2b9ab2",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# consts\n",
    "TUNGUZ_DATASET_REPO_URL = 'https://raw.githubusercontent.com/tunguz/TabularBenchmarks/main/datasets/credit-g/input/'\n",
    "ARFF_DATASET = 'dataset_31_credit-g.arff'\n",
    "RANDOM_SEED = 42\n",
    "TEST_SIZE = .3\n",
    "ISSKEWED = 'isSkewed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bb133e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def categorize_skewness(skew: float) -> str:\n",
    "    magnitude = ''\n",
    "    direction = ''\n",
    "    if abs(skew) <= .5:\n",
    "        magnitude = 'Normal'\n",
    "    elif abs(skew) <= 1:\n",
    "        magnitude = 'Moderate'\n",
    "    elif abs(skew) <= 2:\n",
    "        magnitude = 'High'\n",
    "    elif abs(skew) > 2:\n",
    "        magnitude = 'Extreme'\n",
    "    else:\n",
    "        return 'Undefined'\n",
    "    \n",
    "    if skew == 0:\n",
    "        direction = 'Gaussian'\n",
    "    elif skew > 0:\n",
    "        direction = 'Positive'\n",
    "    else:\n",
    "        direction = 'Negative'\n",
    "    \n",
    "    return f'{magnitude} {direction}'\n",
    "    \n",
    "def categorize_excess_kurtosis(kurt: float) -> str:\n",
    "    if -.5 <= kurt <= .5:\n",
    "        return 'Normal / Mesokurtic'\n",
    "    elif kurt > .5:\n",
    "        return 'Positive / Leptokurtic'\n",
    "    elif kurt < -.5:\n",
    "        return 'Negative / Platykurtic'\n",
    "    else:\n",
    "        return 'Undefined'\n",
    "\n",
    "def is_skewed(skew: float) -> bool:\n",
    "    return abs(skew) > .5\n",
    "\n",
    "def plot_bar(s: pd.Series, figsize: tuple = (9, 7)):\n",
    "    '''Plot nominal label/feature bar purpose only'''\n",
    "    label_counts = s.value_counts()\n",
    "    total = sum(label_counts.values)\n",
    "    desc_series = s.describe()\n",
    "    count, top = int(desc_series[0]), desc_series[2]\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    bars = plt.bar(label_counts.index, label_counts.values)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel(f'{s.name} Label')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(f'Bar Plot of {s.name}')\n",
    "    get_x_right = lambda x, y: ((y - x) * .75) + x\n",
    "    x_right = get_x_right(*plt.gca().get_xlim())\n",
    "    y_min, y_max = plt.gca().get_ylim()\n",
    "    y_range = y_max - y_min\n",
    "\n",
    "    # Adding the counts above the bars\n",
    "    for idx, bar in enumerate(bars):\n",
    "        yval = bar.get_height()\n",
    "        label = label_counts.index[idx]\n",
    "        is_top = label == top\n",
    "        label_text = f\"Top\\n{yval}\\n({yval/total:.2%})\" if is_top else f\"{yval}\\n({yval/total:.2%})\"\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            yval + .1,\n",
    "            label_text,\n",
    "            ha='center',\n",
    "            va='bottom')\n",
    "\n",
    "    # Adding the total count\n",
    "    bbox = dict(boxstyle='round', facecolor='yellow', alpha=.5)\n",
    "    plt.text(\n",
    "        x_right,\n",
    "        .95 * y_range + y_min,\n",
    "        f\"Total: {count}\",\n",
    "        verticalalignment='top',\n",
    "        bbox=bbox\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_histogram(s: pd.Series):\n",
    "    '''Plot numerical features histogram purpose only'''\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    plt.hist(s, bins='auto', edgecolor='black')\n",
    "\n",
    "    desc_series = s.describe()\n",
    "    count = int(desc_series[0])\n",
    "    std = desc_series[2]\n",
    "    min = desc_series[3]\n",
    "    q1 = desc_series[4]\n",
    "    q3 = desc_series[6]\n",
    "    max = desc_series[-1]\n",
    "    mean = s.mean()\n",
    "    median = s.median()\n",
    "    mode = s.mode().values[0]\n",
    "    y_min, y_max = plt.gca().get_ylim()\n",
    "    get_x_center = lambda x, y: ((y - x) * .3) + x\n",
    "    x_center =  get_x_center(*plt.gca().get_xlim())\n",
    "\n",
    "    plt.axvline(min, color='orange', linestyle='solid', linewidth=2)\n",
    "    plt.axvline(max, color='purple', linestyle='solid', linewidth=2)\n",
    "    plt.axvline(q1, color='magenta', linestyle='dashed', linewidth=2)\n",
    "    plt.axvline(median, color='blue', linestyle='dashed', linewidth=2)\n",
    "    plt.axvline(q3, color='cyan', linestyle='dashed', linewidth=2)\n",
    "    plt.axvline(mean, color='red', linestyle='dotted', linewidth=2)\n",
    "    plt.axvline(mode, color='green', linestyle='dashdot', linewidth=2)\n",
    "\n",
    "    y_range = y_max - y_min\n",
    "    y_text = [ i / 10 * y_range + y_min for i in range(1, 8) ]\n",
    "\n",
    "    plt.text(min, y_text[0], f'Min: {min:.2f}', color='orange')\n",
    "    plt.text(max, y_text[1], f'Max: {max:.2f}', color='purple')\n",
    "    plt.text(q1, y_text[2], f'Q1: {q1:.2f}', color='magenta')\n",
    "    plt.text(median, y_text[3], f'Median: {median:.2f}', color='blue')\n",
    "    plt.text(q3, y_text[4], f'Q3: {q3:.2f}', color='cyan')\n",
    "    plt.text(mean, y_text[5], f'Mean: {mean:.2f}', color='red')\n",
    "    plt.text(mode, y_text[6], f'Mode: {mode:.2f}', color='green')\n",
    "\n",
    "    bbox = dict(boxstyle='round', facecolor='yellow', alpha=.5)\n",
    "    plt.text(\n",
    "        x_center,\n",
    "        .95 * y_range + y_min,\n",
    "        f\"Total: {count}\\nStandar deviation: {std:.2f}\",\n",
    "        verticalalignment='top',\n",
    "        bbox=bbox\n",
    "    )\n",
    "\n",
    "    plt.title(f'Histogram of {s.name}')\n",
    "    plt.xlabel('Values')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend({\n",
    "        'Min':min,\n",
    "        'Max':max,\n",
    "        'Q1':q1,\n",
    "        'Median':median,\n",
    "        'Q3':q3,\n",
    "        'Mean':mean,\n",
    "        'Mode':mode\n",
    "        },\n",
    "        loc='upper center',\n",
    "        bbox_to_anchor=(.5,-0.15),\n",
    "        ncol=7\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_bar_histogram(s_bar: pd.Series, s_hist: pd.Series):\n",
    "    '''Plot bar and histogram for side-by-side comparison'''\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(18, 7))\n",
    "\n",
    "    # ===== Bar Plot =====\n",
    "    label_counts = s_bar.value_counts()\n",
    "    total = sum(label_counts.values)\n",
    "    desc_series = s_bar.describe()\n",
    "    count, top = int(desc_series[0]), desc_series[2]\n",
    "    \n",
    "    bars = axs[0].bar(label_counts.index, label_counts.values)\n",
    "    axs[0].set_xticks(range(len(label_counts.index)))\n",
    "    axs[0].set_xticklabels(label_counts.index, rotation=45)\n",
    "    axs[0].set_xlabel(f'{s_bar.name} Label')\n",
    "    axs[0].set_ylabel('Count')\n",
    "    axs[0].set_title(f'Bar Plot of {s_bar.name}')\n",
    "    get_x_right = lambda x, y: ((y - x) * .75) + x\n",
    "    x_right = get_x_right(*axs[0].get_xlim())\n",
    "    y_min, y_max = axs[0].get_ylim()\n",
    "    y_range = y_max - y_min\n",
    "\n",
    "    for idx, bar in enumerate(bars):\n",
    "        yval = bar.get_height()\n",
    "        label = label_counts.index[idx]\n",
    "        is_top = label == top\n",
    "        label_text = f\"Top\\n{yval}\\n({yval/total:.2%})\" if is_top else f\"{yval}\\n({yval/total:.2%})\"\n",
    "        axs[0].text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            yval + .1,\n",
    "            label_text,\n",
    "            ha='center',\n",
    "            va='bottom')\n",
    "\n",
    "    # Adding the total count\n",
    "    bbox = dict(boxstyle='round', facecolor='yellow', alpha=.5)\n",
    "    axs[0].text(\n",
    "        x_right,\n",
    "        .95 * y_range + y_min,\n",
    "        f\"Total: {count}\",\n",
    "        verticalalignment='top',\n",
    "        bbox=bbox\n",
    "    )\n",
    "    \n",
    "    # ===== Histogram Plot =====\n",
    "    axs[1].hist(s_hist, bins='auto', edgecolor='black')\n",
    "    desc_series = s_hist.describe()\n",
    "    count = int(desc_series[0])\n",
    "    std = desc_series[2]\n",
    "    min = desc_series[3]\n",
    "    q1 = desc_series[4]\n",
    "    q3 = desc_series[6]\n",
    "    max = desc_series[-1]\n",
    "    mean = s_hist.mean()\n",
    "    median = s_hist.median()\n",
    "    mode = s_hist.mode().values[0]\n",
    "\n",
    "    y_min, y_max = axs[1].get_ylim()\n",
    "    get_x_center = lambda x, y: ((y - x) * .3) + x\n",
    "    x_center = get_x_center(*axs[1].get_xlim())\n",
    "\n",
    "    axs[1].axvline(min, color='orange', linestyle='solid', linewidth=2)\n",
    "    axs[1].axvline(max, color='purple', linestyle='solid', linewidth=2)\n",
    "    axs[1].axvline(q1, color='magenta', linestyle='dashed', linewidth=2)\n",
    "    axs[1].axvline(median, color='blue', linestyle='dashed', linewidth=2)\n",
    "    axs[1].axvline(q3, color='cyan', linestyle='dashed', linewidth=2)\n",
    "    axs[1].axvline(mean, color='red', linestyle='dotted', linewidth=2)\n",
    "    axs[1].axvline(mode, color='green', linestyle='dashdot', linewidth=2)\n",
    "\n",
    "    y_range = y_max - y_min\n",
    "    y_text = [ i / 10 * y_range + y_min for i in range(1,8) ]\n",
    "    \n",
    "    axs[1].text(min, y_text[0], f'Min: {min:.2f}', color='orange')\n",
    "    axs[1].text(max, y_text[1], f'Max: {max:.2f}', color='purple')\n",
    "    axs[1].text(q1, y_text[2], f'Q1: {q1:.2f}', color='magenta')\n",
    "    axs[1].text(median, y_text[3], f'Median: {median:.2f}', color='blue')\n",
    "    axs[1].text(q3, y_text[4], f'Q3: {q3:.2f}', color='cyan')\n",
    "    axs[1].text(mean, y_text[5], f'Mean: {mean:.2f}', color='red')\n",
    "    axs[1].text(mode, y_text[6], f'Mode: {mode:.2f}', color='green')\n",
    "\n",
    "    bbox = dict(boxstyle='round', facecolor='yellow', alpha=.5)\n",
    "    axs[1].text(\n",
    "        x_center,\n",
    "        .95 * y_range + y_min,\n",
    "        f\"Total: {count}\\nStandard deviation: {std:.2f}\",\n",
    "        verticalalignment='top',\n",
    "        bbox=bbox\n",
    "    )\n",
    "\n",
    "    axs[1].set_title(f'Histogram of {s_hist.name}')\n",
    "    axs[1].set_xlabel('Values')\n",
    "    axs[1].set_ylabel('Frequency')\n",
    "    axs[1].legend({\n",
    "        'Min':min,\n",
    "        'Max':max,\n",
    "        'Q1':q1,\n",
    "        'Median':median,\n",
    "        'Q3':q3,\n",
    "        'Mean':mean,\n",
    "        'Mode':mode\n",
    "        },\n",
    "        loc='upper center',\n",
    "        bbox_to_anchor=(.5,-0.15),\n",
    "        ncol=7\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_histogram_comparison(train_series: pd.Series, test_series: pd.Series):\n",
    "    '''Plot 2 features histogram side by side for comparison purpose only'''\n",
    "    sequences = ('Train', 'Test')\n",
    "    _, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "    \n",
    "    for s, ax, seq in zip((train_series, test_series), axes, sequences):\n",
    "        ax.hist(s, bins='auto', edgecolor='black')\n",
    "\n",
    "        desc_series = s.describe()\n",
    "        count = int(desc_series[0])\n",
    "        std = desc_series[2]\n",
    "        min = desc_series[3]\n",
    "        q1 = desc_series[4]\n",
    "        q3 = desc_series[6]\n",
    "        max = desc_series[-1]\n",
    "        mean = s.mean()\n",
    "        median = s.median()\n",
    "        mode = s.mode().values[0]\n",
    "        skewness = s.skew()\n",
    "        kurtosis = s.kurt()\n",
    "        skew_category = categorize_skewness(skewness)\n",
    "        kurt_category = categorize_excess_kurtosis(kurtosis)\n",
    "        \n",
    "        y_min, y_max = ax.get_ylim()\n",
    "        get_x_center = lambda x, y: ((y - x) * .25) + x\n",
    "        x_center =  get_x_center(*ax.get_xlim())\n",
    "\n",
    "        ax.axvline(min, color='orange', linestyle='solid', linewidth=2)\n",
    "        ax.axvline(max, color='purple', linestyle='solid', linewidth=2)\n",
    "        ax.axvline(q1, color='magenta', linestyle='dashed', linewidth=2)\n",
    "        ax.axvline(median, color='blue', linestyle='dashed', linewidth=2)\n",
    "        ax.axvline(q3, color='cyan', linestyle='dashed', linewidth=2)\n",
    "        ax.axvline(mean, color='red', linestyle='dotted', linewidth=2)\n",
    "        ax.axvline(mode, color='green', linestyle='dashdot', linewidth=2)\n",
    "\n",
    "        y_range = y_max - y_min\n",
    "        y_text = [ i / 12 * y_range + y_min for i in range(1, 8) ]\n",
    "\n",
    "        ax.text(min, y_text[0], f'Min: {min:.2f}', color='orange')\n",
    "        ax.text(max, y_text[1], f'Max: {max:.2f}', color='purple')\n",
    "        ax.text(q1, y_text[2], f'Q1: {q1:.2f}', color='magenta')\n",
    "        ax.text(median, y_text[3], f'Median: {median:.2f}', color='blue')\n",
    "        ax.text(q3, y_text[4], f'Q3: {q3:.2f}', color='cyan')\n",
    "        ax.text(mean, y_text[5], f'Mean: {mean:.2f}', color='red')\n",
    "        ax.text(mode, y_text[6], f'Mode: {mode:.2f}', color='green')\n",
    "        \n",
    "        bbox = dict(boxstyle='round', facecolor='yellow', alpha=.5)\n",
    "        ax.text(\n",
    "            x_center,\n",
    "            .95 * y_range + y_min,\n",
    "            f\"Total: {count}\\nStandard deviation: {std:.2f}\\n\"\n",
    "            f\"Kurtosis: {kurtosis:.2f} ({kurt_category})\\n\"\n",
    "            f\"Skewness: {skewness:.2f} ({skew_category})\",\n",
    "            verticalalignment='top',\n",
    "            bbox=bbox\n",
    "        )\n",
    "\n",
    "        ax.set_title(f'{seq}: Histogram of \"{s.name}\"')\n",
    "        ax.set_xlabel('Values')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.legend({\n",
    "            'Min':min,\n",
    "            'Max':max,\n",
    "            'Q1':q1,\n",
    "            'Median':median,\n",
    "            'Q3':q3,\n",
    "            'Mean':mean,\n",
    "            'Mode':mode\n",
    "            },\n",
    "            loc='upper center',\n",
    "            bbox_to_anchor=(.5,-0.15),\n",
    "            ncol=4\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_histogram_sk(s: pd.Series):\n",
    "    '''Plot numerical features histogram with skewness and kurtosis addition'''\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    plt.hist(s, bins='auto', edgecolor='black')\n",
    "\n",
    "    desc_series = s.describe()\n",
    "    count = int(desc_series[0])\n",
    "    std = desc_series[2]\n",
    "    min = desc_series[3]\n",
    "    q1 = desc_series[4]\n",
    "    q3 = desc_series[6]\n",
    "    max = desc_series[-1]\n",
    "    mean = s.mean()\n",
    "    median = s.median()\n",
    "    mode = s.mode().values[0]\n",
    "    skewness = s.skew()\n",
    "    kurtosis = s.kurt()\n",
    "    skew_category = categorize_skewness(skewness)\n",
    "    kurt_category = categorize_excess_kurtosis(kurtosis)\n",
    "\n",
    "    y_min, y_max = plt.gca().get_ylim()\n",
    "    get_x_center = lambda x, y: ((y - x) * .25) + x\n",
    "    x_center =  get_x_center(*plt.gca().get_xlim())\n",
    "\n",
    "    plt.axvline(min, color='orange', linestyle='solid', linewidth=2)\n",
    "    plt.axvline(max, color='purple', linestyle='solid', linewidth=2)\n",
    "    plt.axvline(q1, color='magenta', linestyle='dashed', linewidth=2)\n",
    "    plt.axvline(median, color='blue', linestyle='dashed', linewidth=2)\n",
    "    plt.axvline(q3, color='cyan', linestyle='dashed', linewidth=2)\n",
    "    plt.axvline(mean, color='red', linestyle='dotted', linewidth=2)\n",
    "    plt.axvline(mode, color='green', linestyle='dashdot', linewidth=2)\n",
    "\n",
    "    y_range = y_max - y_min\n",
    "    y_text = [ i / 12 * y_range + y_min for i in range(1, 8) ]\n",
    "\n",
    "    plt.text(min, y_text[0], f'Min: {min:.2f}', color='orange')\n",
    "    plt.text(max, y_text[1], f'Max: {max:.2f}', color='purple')\n",
    "    plt.text(q1, y_text[2], f'Q1: {q1:.2f}', color='magenta')\n",
    "    plt.text(median, y_text[3], f'Median: {median:.2f}', color='blue')\n",
    "    plt.text(q3, y_text[4], f'Q3: {q3:.2f}', color='cyan')\n",
    "    plt.text(mean, y_text[5], f'Mean: {mean:.2f}', color='red')\n",
    "    plt.text(mode, y_text[6], f'Mode: {mode:.2f}', color='green')\n",
    "\n",
    "    bbox = dict(boxstyle='round', facecolor='yellow', alpha=.5)\n",
    "    plt.text(\n",
    "        x_center,\n",
    "        .95 * y_range + y_min,\n",
    "        f\"Total: {count}\\nStandard deviation: {std:.2f}\\n\"\n",
    "        f\"Kurtosis: {kurtosis:.2f} ({kurt_category})\\n\"\n",
    "        f\"Skewness: {skewness:.2f} ({skew_category})\",\n",
    "        verticalalignment='top',\n",
    "        bbox=bbox\n",
    "    )\n",
    "\n",
    "    plt.title(f'Histogram of {s.name}')\n",
    "    plt.xlabel('Values')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend({\n",
    "        'Min':min,\n",
    "        'Max':max,\n",
    "        'Q1':q1,\n",
    "        'Median':median,\n",
    "        'Q3':q3,\n",
    "        'Mean':mean,\n",
    "        'Mode':mode\n",
    "        },\n",
    "        loc='upper center',\n",
    "        bbox_to_anchor=(.5,-0.15),\n",
    "        ncol=7\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_raincloud_comparison(train_series: pd.Series, test_series: pd.Series):\n",
    "    '''Plot 2 features raincloud side by side for comparison purpose only'''\n",
    "    df1 = pd.DataFrame({train_series.name: train_series, 'Group': 'Train'})\n",
    "    df2 = pd.DataFrame({test_series.name: test_series, 'Group': 'Test'})\n",
    "    df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    plt.figure(figsize=(18, 7))\n",
    "    _ = pt.RainCloud(\n",
    "        x='Group',\n",
    "        y=train_series.name,\n",
    "        data=df,\n",
    "        width_viol=.6,\n",
    "        width_box=.2,\n",
    "        orient='h',\n",
    "        ax=None,\n",
    "        move=0\n",
    "    )\n",
    "\n",
    "    plt.title(f'Raincloud Plot Comparison of {train_series.name}')\n",
    "    plt.xlabel('Values')\n",
    "    plt.ylabel('Density')\n",
    "    plt.show()\n",
    "\n",
    "def check_missing_df(df: pd.DataFrame):\n",
    "    '''Check missing data on features only'''\n",
    "    total_values = df.size\n",
    "    if df.isnull().any().any():\n",
    "        print(\"There are missing values in the dataframe.\")\n",
    "        if df.isnull().any().sum() > 0:\n",
    "            print(\"\\nColumns with missing values:\")\n",
    "            print(df.isnull().sum()[df.isnull().sum() > 0])\n",
    "        total_missing = df.isnull().sum().sum()\n",
    "        print(\"\\nTotal number of missing values: \", total_missing)\n",
    "        print(f\"Ratio of missing values: {total_missing}/{total_values} = {total_missing / total_values:.2}\")\n",
    "        print(f\"Percentage of missing values = {total_missing / total_values:.2%}\")\n",
    "    else:\n",
    "        print(\"There are no missing values in the dataframe.\")\n",
    "\n",
    "def check_missing_s(s: pd.Series):\n",
    "    '''Check missing data on labels only'''\n",
    "    total_values = s.size\n",
    "    if s.isnull().any():\n",
    "        print(\"There are missing values in the series.\")\n",
    "        total_missing = s.isnull().sum()\n",
    "        print(\"Total number of missing values: \", total_missing)\n",
    "        print(f\"Ratio of missing values: {total_missing}/{total_values} = {total_missing / total_values:.2}\")\n",
    "        print(f\"Percentage of missing values = {total_missing / total_values:.2%}\")\n",
    "    else:\n",
    "        print(\"There are no missing values in the series.\")\n",
    "\n",
    "def check_duplicates_df(df: pd.DataFrame):\n",
    "    '''Check duplicate data on DataFrame'''\n",
    "    total_rows = df.shape[0]\n",
    "    if df.duplicated().any():\n",
    "        print(\"There are duplicated rows in the dataframe.\")\n",
    "        total_duplicates = df.duplicated().sum()\n",
    "        print(f\"\\nTotal number of duplicated rows: {total_duplicates}\")\n",
    "        print(f\"Ratio of duplicated rows: {total_duplicates}/{total_rows} = {total_duplicates / total_rows:.2}\")\n",
    "        print(f\"Percentage of duplicated rows = {total_duplicates / total_rows:.2%}\")\n",
    "\n",
    "        # Print duplicated rows (showing first few rows)\n",
    "        duplicated_rows = df[df.duplicated()]\n",
    "        print(\"\\nPreview of duplicated rows:\")\n",
    "        print(duplicated_rows)\n",
    "    else:\n",
    "        print(\"There are no duplicated rows in the dataframe.\")\n",
    "\n",
    "def desc_stats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''Return descriptive statistics of the given dataframe'''\n",
    "    desc_stats_df = df.describe()\n",
    "    skewness = df.apply(lambda x: round(x.skew(), 6)).to_frame().T\n",
    "    kurtosis = df.apply(lambda x: round(x.kurt(), 6)).to_frame().T\n",
    "    is_skewed_df = skewness.applymap(is_skewed)\n",
    "    skewness.index = ['skew']\n",
    "    kurtosis.index = ['kurt']\n",
    "    is_skewed_df.index = [ISSKEWED]\n",
    "    desc_stats_df = pd.concat([desc_stats_df, skewness, kurtosis, is_skewed_df])\n",
    "    return desc_stats_df\n",
    "\n",
    "def get_skewed_features(desc_stats_df = pd.DataFrame) -> set:\n",
    "    '''Return set of skewed features given the dataframe'''\n",
    "    skewed_features = desc_stats_df.loc[ISSKEWED] == True\n",
    "    skewed_features = {*skewed_features[skewed_features == True].index.tolist()}\n",
    "    return skewed_features\n",
    "\n",
    "def get_difference_set(left_set: set, right_set: set) -> dict:\n",
    "    '''Return the difference between two sets'''\n",
    "    return {\n",
    "        'left_set': left_set - right_set,\n",
    "        'right_set': right_set - left_set\n",
    "        }\n",
    "\n",
    "def get_union_set(set1: set, set2: set) -> list:\n",
    "    '''Return the union of the given sets'''\n",
    "    return list(set1 | set2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5ffb1c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "app = mr.App(\n",
    "    title=\"German Credit EDA üìä\",\n",
    "    description=\"Interactive Presentation of German Credit Explanatory Data Analysis\",\n",
    "    stop_on_error=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fb8c05",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mr.Markdown(\"# German Credit EDA - Interactive Presentation üìù\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf4f163",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"## Recompute Slides Hints üíª\n",
    "\n",
    "- This is powered by <a href='https://github.com/mljar/mercury' target='_blank'>Mercury</a>\n",
    "- You can interact with all available widgets\n",
    "- Enter full screen by pressing **F** and exit with **Esc**\n",
    "- Use ‚óÄ ‚ñ∂ for slide navigation\n",
    "- Use üîº üîΩ for subslide / fragment navigation\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a4ee065",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea55d9d8-d00a-4219-9c3c-ab398d36a1bb",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# loading the arrf dataset\n",
    "url = f'{TUNGUZ_DATASET_REPO_URL}{ARFF_DATASET}'\n",
    "\n",
    "if os.path.exists(ARFF_DATASET):\n",
    "    with open(ARFF_DATASET, 'rt') as f:\n",
    "        data, meta = arff.loadarff(f)\n",
    "else:\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(ARFF_DATASET, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        # Reopen the file in text mode for reading with arff.loadarff\n",
    "        with open(ARFF_DATASET, 'rt') as f:\n",
    "            data, meta = arff.loadarff(f)\n",
    "    else:\n",
    "        print(f\"Couldn't download the file: {url}\")\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e77e7443",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Attribute Description ‚öí\n",
    "\n",
    "Features:\n",
    "\n",
    "| no | attribute | unique_values | description | nominal | ordinal | ratio |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| 1 | `checking_status` | ['<0', '0<=X<200', 'no checking', '>=200'] |  Status of existing checking account. **People with lower balances might be seen as higher risk.** | ‚úî | there are order | - |\n",
    "| 2 | `duration` | [4, 72] **inclusive range not unique values** | Duration in month. **Longer loan durations might be riskier as they offer more opportunities for the borrower's circumstances to change.** | - | long or short | ‚úî |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7496e289",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "| no | attribute | unique_values | description | nominal | ordinal | ratio |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| 3 | `credit_history` | ['critical/other existing credit', 'existing paid', 'delayed previously', 'no credits/all paid', 'all paid'] | The applicant‚Äôs track record in terms of past loans. **A history of delinquency could point to higher risk.** | ‚úî | - | - |\n",
    "| 4 | `purpose` | ['radio/tv', 'education', 'furniture/equipment', 'new car', 'used car', 'business', 'domestic appliance', 'repairs', 'other', 'retraining'] | Purpose for the loan. **Certain loan purposes might be associated with higher risk than others (e.g., starting a new business might be riskier than buying a car).** | ‚úî | - | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb8ea19",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "| no | attribute | unique_values | description | nominal | ordinal | ratio |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| 5 | `credit_amount` | [250, 18424] **inclusive range not unique values** | The amount of loan in question. **Larger loans might be considered higher risk.** | - | small or big | ‚úî |\n",
    "| 6 | `savings_status` | ['no known savings', '<100', '500<=X<1000', '>=1000', '100<=X<500'] | Savings account/bonds. **Those with more savings might be considered lower risk.** | ‚úî | there are order | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3989dab4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "| no | attribute | unique_values | description | nominal | ordinal | ratio |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| 7 | `employment` | ['>=7', '1<=X<4', '4<=X<7', 'unemployed', '<1'] | Present employment since. **Longer employment might be seen as indicating more stable income.** | ‚úî | there are order | - |\n",
    "| 8 | `installment_commitment` | [1, 2, 3, 4] | Installment rate in percentage of disposable income. **Higher percentages could indicate financial strain and higher risk.** | - | low or high | ‚úî |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9ac10c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "| no | attribute | unique_values | description | nominal | ordinal | ratio |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| 9 | `personal_status` | ['male single', 'female div/dep/mar', 'male div/sep', 'male mar/wid'] | Personal status and sex includes marital status and gender. **These factors could have complex interactions with risk.** | ‚úî | - | - |\n",
    "| 10 | `other_parties` | ['none', 'guarantor', 'co applicant'] | Other debtors / guarantors that indicates if there are other people who share the responsibility of the loan. **Guarantors can decrease the risk.** | ‚úî | - | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f72093",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "| no | attribute | unique_values | description | nominal | ordinal | ratio |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| 11 | `residence_since` | [1, 2, 3, 4] | How long the applicant has lived at their current address. **Longer times could indicate more stability.** | - | long or short | ‚úî |\n",
    "| 12 | `property_magnitude` | ['real estate', 'life insurance', 'no known property', 'car'] | Describes the types of property the person owns. **Describes the types of property the person owns.** | ‚úî | - | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e2c098",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "| no | attribute | unique_values | description | nominal | ordinal | ratio |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| 13 | `age` | [19, 75] **inclusive range not unique values** | The applicant‚Äôs age. **Risk can vary with age due to factors like income stability, health status, etc.** | - | older or younger | ‚úî |\n",
    "| 14 | `other_payment_plans` | ['none', 'bank', 'stores'] | Other installment plans that indicates if the borrower has other ongoing loans. **Additional financial obligations can increase risk.** | ‚úî | - | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc6f028",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "| no | attribute | unique_values | description | nominal | ordinal | ratio |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| 15 | `housing` | ['own', 'for free', 'rent'] | The type of housing the applicant lives in. **Those who own their homes might be seen as more stable/less risky.** | ‚úî | - | - |\n",
    "| 16 | `existing_credits` | [1, 2, 3, 4] | Number of existing credits at this bank. **Multiple loans could indicate higher risk.** | - | few or many | ‚úî |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e476f8a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "| no | attribute | unique_values | description | nominal | ordinal | ratio |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| 17 | `job` | ['skilled', 'unskilled resident', 'high qualif/self emp/mgmt', 'unemp/unskilled non res'] | The applicant's job status and type. **Certain jobs might be seen as more stable/less risky.** | ‚úî | - | - |\n",
    "| 18 | `num_dependents` | [1, 2] | Number of people being liable to provide maintenance for. **The more dependents person has, the more of their income is likely already spoken for, which can make it riskier for the bank to lend them money.** | - | - | ‚úî |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f781e1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "| no | attribute | unique_values | description | nominal | ordinal | ratio |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| 19 | `own_telephone` | ['yes', 'none'] | Indicates if the applicant has a telephone registered under their name. **This could be seen as a sign of stability.** | ‚úî | - | - |\n",
    "| 20 | `foreign_worker` | ['yes', 'no'] | Indicates if the applicant is a foreign worker. **Foreign workers might be seen as higher risk due to potential job and legal uncertainties.** | ‚úî | - | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140cf093",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And the label:\n",
    "\n",
    "| no | label | unique_values | description | nominal | ordinal | ratio |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| 1 | `class` | ['good', 'bad'] | Label that indicates whether the applicant is good or bad for the credit. | ‚úî | - | - |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "157bcacc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**NB:**\n",
    "\n",
    "- There is no any nominal column that comes in a **pure numeric** form, so it is **safe for encoding** later\n",
    "- **Ordinal attributes** could be made out from **either nominal or ratio attributes**, but for now we just stick with the original nominal and ratio attributes\n",
    "- Because of the previous statement, there are a lot combination set of features to try on to get the optimal features for predictive model to train to\n",
    "- Notice `personal_status`, which is a composite feature that includes both `gender` and `marital status`. In our current approach, these features are combined into a single attribute. However, it is possible that separating these features might provide different insights and potentially improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2274341e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d26797",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# convert the byte string into regular string and numeric into their best data type\n",
    "df = df.convert_dtypes()\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = df[col].str.decode('utf-8')\n",
    "\n",
    "# separating the features from the labels\n",
    "features = df.drop('class', axis=1)\n",
    "labels = df['class']\n",
    "nominal_columns = features.select_dtypes(include='object').columns.to_list()\n",
    "feature_columns = features.columns.to_list()\n",
    "\n",
    "# split into train and test split to prevent data leakage\n",
    "# stratify since we have the imbalanced classes and minority class\n",
    "# and ensure consistent representation for training dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    features,\n",
    "    labels,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_SEED,\n",
    "    shuffle=True,\n",
    "    stratify=labels\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "554cce27",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exploratory Data Analysis (EDA) üìä"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b937b76",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### LeaveOneOut Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216abb01",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# represent nominal columns in numerical way with Leave-One-Out Encoding\n",
    "loo_encoder = LeaveOneOutEncoder(drop_invariant=True, return_df=True)\n",
    "label_encoder = LabelEncoder()\n",
    "numeric_x_train = loo_encoder.fit_transform(x_train, label_encoder.fit_transform(y_train))\n",
    "numeric_x_test = loo_encoder.transform(x_test)\n",
    "numeric_x_train = numeric_x_train.astype(float)\n",
    "numeric_x_test = numeric_x_test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c9af51",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "_ = mr.Note(text='---')\n",
    "is_train_dataset = mr.Checkbox(\n",
    "    label='Train dataset',\n",
    "    value=True\n",
    ")\n",
    "\n",
    "_ = mr.Note(text='---')\n",
    "_ = mr.Note(text='**Leave One Out Encoding Transformation**')\n",
    "nominal_selection = mr.Select(\n",
    "    label='Nominal column',\n",
    "    value=nominal_columns[0],\n",
    "    choices=nominal_columns\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f7e47b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"### Leave One Out Encoding üìä\n",
    "Please change `Train dataset` and `Nominal column` to see the changes before and after the encoding in particular dataset.\n",
    "The plot will automatically updated. See the individual plot on the below subslides.\n",
    "\"\"\")\n",
    "if is_train_dataset.value:\n",
    "    plot_bar_histogram(x_train[nominal_selection.value], numeric_x_train[nominal_selection.value])\n",
    "else:\n",
    "    plot_bar_histogram(x_test[nominal_selection.value], numeric_x_test[nominal_selection.value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39da14a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "if is_train_dataset.value:\n",
    "    plot_bar(x_train[nominal_selection.value])\n",
    "else:\n",
    "    plot_bar(x_test[nominal_selection.value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c9bd1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "if is_train_dataset.value:\n",
    "    plot_histogram(numeric_x_train[nominal_selection.value])\n",
    "else:\n",
    "    plot_histogram(numeric_x_test[nominal_selection.value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03893f10",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mr.Markdown(f\"\"\" ### Check Missing Data ‚úÖ\n",
    "Train Dataset:\"\"\")\n",
    "check_missing_df(numeric_x_train)\n",
    "check_missing_s(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a322eb1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mr.Markdown(\"Test Dataset:\")\n",
    "check_missing_df(numeric_x_test)\n",
    "check_missing_s(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e085e499",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mr.Markdown(f\"\"\" ### Check Duplicated Data ‚òë\n",
    "Train Dataset:\"\"\")\n",
    "check_duplicates_df(numeric_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f504e67",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mr.Markdown(\"Test Dataset:\")\n",
    "check_duplicates_df(numeric_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6ae396",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f94f302",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "_ = mr.Note(text='---')\n",
    "_ = mr.Note(text='**Descriptive Statistics & Histogram** (after Leave One Out Encoding)')\n",
    "_ = mr.Note(text='**Raincloud Plot**')\n",
    "feature_selection = mr.Select(\n",
    "    label='Feature column',\n",
    "    value=feature_columns[0],\n",
    "    choices=feature_columns\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754f50b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"### Descriptive Statistics & Histogram üìà\n",
    "Please change `Feature column` to see particular feature from both datasets.\n",
    "The plot will automatically updated. See the individual plot on the below subslides.\n",
    "For now we just focus on skewness of the feature and let information of the kurtosis be the complement.\n",
    "If the skewness category is not normal, we transform it later.\n",
    "\"\"\")\n",
    "\n",
    "plot_histogram_comparison(\n",
    "    numeric_x_train[feature_selection.value],\n",
    "    numeric_x_test[feature_selection.value]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4112ca",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mr.Markdown('Train Dataset:')\n",
    "plot_histogram_sk(numeric_x_train[feature_selection.value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5657d68",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mr.Markdown('Test Dataset:')\n",
    "plot_histogram_sk(numeric_x_test[feature_selection.value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58af2d4a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"### Raincloud Plot üåß\n",
    "Please change `Feature column` to see particular feature from both datasets.\n",
    "The plot will automatically updated.\n",
    "\"\"\")\n",
    "\n",
    "plot_raincloud_comparison(\n",
    "    numeric_x_train[feature_selection.value],\n",
    "    numeric_x_test[feature_selection.value]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ae770e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x_train_desc_stats_df = desc_stats(numeric_x_train)\n",
    "x_test_desc_stats_df = desc_stats(numeric_x_test)\n",
    "x_train_skewed_features = get_skewed_features(x_train_desc_stats_df)\n",
    "x_test_skewed_features = get_skewed_features(x_test_desc_stats_df)\n",
    "diff_features = get_difference_set(x_train_skewed_features, x_test_skewed_features)\n",
    "\n",
    "skewed_feature_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "    'Train': list(x_train_skewed_features),\n",
    "    'Test': list(x_test_skewed_features),\n",
    "    'Train-Test': list(diff_features['left_set']),\n",
    "    'Test-Train': list(diff_features['right_set']),\n",
    "    'Train|Test': get_union_set(x_train_skewed_features, x_test_skewed_features)\n",
    "    },\n",
    "    orient='index')\n",
    "skewed_feature_df = skewed_feature_df.transpose()\n",
    "\n",
    "mr.Markdown('### Skewed Features across Dataset üìâ')\n",
    "display(skewed_feature_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dda1735",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**NB:**\n",
    "\n",
    "We can see there is a different of skewed data between train and test dataset in `other_parties` feature. For now, we will transform both of `other_parties` since the visual support this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79038993",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mr.Markdown(\"\"\"### Imbalanced Dataset ‚öñ\n",
    "Please change `Train dataset` to see label distribution from given dataset.\n",
    "The plot will automatically updated.\"\"\")\n",
    "\n",
    "if is_train_dataset.value:\n",
    "    plot_bar(y_train, (7, 5))\n",
    "else:\n",
    "    plot_bar(y_test, (7, 5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d149865",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**NB:**\n",
    "\n",
    "- The dataset is imbalance which can make a predictive model tend to bias on the majority of the class (`good`)\n",
    "- We use **Cost-Sensitive Training** method here and **avoid** to use **SMOTE** method:\n",
    "    - ‚ùå **Synthetic Minority Oversampling TEchnique (SMOTE)**: works by creating synthetic samples from the minority class instead of creating copies. The algorithm selects two or more similar instances (using a distance measure) and perturbing an instance one attribute at a time by a random amount within the difference to the neighboring instances. **Here's why we need to avoid this method**: <a href='https://www.linkedin.com/feed/update/urn:li:activity:7102668506399137793' target='_blank'>TLDR SMOTE is Smoked</a>\n",
    "    - ‚úÖ **Cost-Sensitive Training**: giving a higher penalty to misclassified minority classes during the training of the machine learning algorithm (using the `cost-matrix` based on the arrf dataset comment). It changes the algorithm's objective function to penalize mistakes on the minority class more heavily. This can make the model pay more attention to the minority class, but it doesn't help the model learn more about the structure of the minority class's data, like SMOTE does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d4f974",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The `cost-matrix` as follows:\n",
    "\n",
    "| | Good | Bad |\n",
    "|---|---|---|\n",
    "| **Good** | 0 | 1 |\n",
    "| **Bad** | 5 | 0 |\n",
    "\n",
    "The **rows** represent the **actual** classification and the **columns** the **predicted** classification. It is **worse** to class a customer **as good** when they **are bad (5)**, than it is to class a customer **as bad** when they **are good (1)**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f342757",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "- <a href='https://github.com/mljar/mercury' target='_blank'>Mercury GitHub</a>\n",
    "- <a href='https://runmercury.com/tutorials/presentation-python-jupyter-notebook/' target='_blank'>Create interactive slides with Python in 8 Jupyter Notebook cells</a>\n",
    "- <a href='https://raw.githubusercontent.com/tunguz/TabularBenchmarks/main/datasets/credit-g/input/' target='_blank'>German Credit Dataset</a>\n",
    "- <a href='https://medium.com/analytics-vidhya/stop-one-hot-encoding-your-categorical-variables-bbb0fba89809' target='_blank'>Stop One-Hot Encoding Your Categorical Variables</a>\n",
    "- <a href='https://medium.com/@kaoningyu/dont-use-one-hot-encoding-anymore-25b5882e533f' target='_blank'>Don‚Äôt use One-Hot Encoding Anymore!!!</a>\n",
    "- <a href='https://www.linkedin.com/feed/update/urn:li:activity:7105222235015053312/' target='_blank'>Raincloud Plots - LinkedIn Post</a>\n",
    "- <a href='https://www.linkedin.com/feed/update/urn:li:activity:7102668506399137793' target='_blank'>TLDR SMOTE is Smoked</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
